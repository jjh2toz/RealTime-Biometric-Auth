{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excessive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inner-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attempted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "competitive-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 10\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "velvet-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 235, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 231, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 47, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.4877531154485289),\n",
    "        layers.LSTM(46),\n",
    "        layers.Dense(13, activation = 'relu'),\n",
    "        layers.Dense(187, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 16, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 8, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.LSTM(20),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(5, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "renewable-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 480, 235)          1645      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 160, 235)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 160, 231)          163086    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 53, 231)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 53, 47)            32618     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 17, 47)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 47)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 46)                17296     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 13)                611       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 187)               2618      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 188       \n",
      "=================================================================\n",
      "Total params: 218,062\n",
      "Trainable params: 218,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.5335 - binary_accuracy: 0.7483\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 0.4252 - binary_accuracy: 0.7933\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 0.3757 - binary_accuracy: 0.8211\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 6s 29ms/step - loss: 0.3478 - binary_accuracy: 0.8489\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 0.3177 - binary_accuracy: 0.8674\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 0.3126 - binary_accuracy: 0.8645\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 0.2892 - binary_accuracy: 0.8764\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.2855 - binary_accuracy: 0.8805\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.2642 - binary_accuracy: 0.8869\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.2407 - binary_accuracy: 0.8969\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.2249 - binary_accuracy: 0.9068\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.2146 - binary_accuracy: 0.9106\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.2192 - binary_accuracy: 0.9106\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.2036 - binary_accuracy: 0.9171\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1890 - binary_accuracy: 0.9256\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1976 - binary_accuracy: 0.9206\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1792 - binary_accuracy: 0.9313\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.1651 - binary_accuracy: 0.9404\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1540 - binary_accuracy: 0.9413\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1547 - binary_accuracy: 0.9406\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1502 - binary_accuracy: 0.9437\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1352 - binary_accuracy: 0.9518\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1432 - binary_accuracy: 0.9458\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1291 - binary_accuracy: 0.9499\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1247 - binary_accuracy: 0.9518\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1226 - binary_accuracy: 0.9529\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.1127 - binary_accuracy: 0.9553\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1143 - binary_accuracy: 0.9579\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.1083 - binary_accuracy: 0.9601\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.1137 - binary_accuracy: 0.9598\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.1004 - binary_accuracy: 0.9651\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.0906 - binary_accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.0864 - binary_accuracy: 0.9693\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0897 - binary_accuracy: 0.9708\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.0937 - binary_accuracy: 0.9677\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0806 - binary_accuracy: 0.9720\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0822 - binary_accuracy: 0.9684\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 0.0831 - binary_accuracy: 0.9689\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0655 - binary_accuracy: 0.9777\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0643 - binary_accuracy: 0.9760\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0573 - binary_accuracy: 0.9812\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0737 - binary_accuracy: 0.9736\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0616 - binary_accuracy: 0.9796\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0643 - binary_accuracy: 0.9750\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0624 - binary_accuracy: 0.9753\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0454 - binary_accuracy: 0.9836\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0475 - binary_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0485 - binary_accuracy: 0.9834\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0494 - binary_accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0464 - binary_accuracy: 0.9831\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0509 - binary_accuracy: 0.9812\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0626 - binary_accuracy: 0.9786\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0470 - binary_accuracy: 0.9846\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0409 - binary_accuracy: 0.9865\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0407 - binary_accuracy: 0.9865\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0425 - binary_accuracy: 0.9836\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0431 - binary_accuracy: 0.9865\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0407 - binary_accuracy: 0.9865\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0390 - binary_accuracy: 0.9872\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0336 - binary_accuracy: 0.9884\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0497 - binary_accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0301 - binary_accuracy: 0.9914\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0376 - binary_accuracy: 0.9850\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0289 - binary_accuracy: 0.9900\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0321 - binary_accuracy: 0.9898\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0249 - binary_accuracy: 0.9926\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0422 - binary_accuracy: 0.9850\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.0358 - binary_accuracy: 0.9874\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0344 - binary_accuracy: 0.9874\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0214 - binary_accuracy: 0.9926\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0642 - binary_accuracy: 0.9767\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.0182 - binary_accuracy: 0.9948\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0287 - binary_accuracy: 0.9895\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0196 - binary_accuracy: 0.9929\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0242 - binary_accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0264 - binary_accuracy: 0.9907\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0313 - binary_accuracy: 0.9881\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0298 - binary_accuracy: 0.9893\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0268 - binary_accuracy: 0.9895\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0274 - binary_accuracy: 0.9903\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0240 - binary_accuracy: 0.9919\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0236 - binary_accuracy: 0.9929\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.0199 - binary_accuracy: 0.9933\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0159 - binary_accuracy: 0.9948\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0315 - binary_accuracy: 0.9898\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0184 - binary_accuracy: 0.9936\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0165 - binary_accuracy: 0.9945\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0274 - binary_accuracy: 0.9895\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0276 - binary_accuracy: 0.9907\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0198 - binary_accuracy: 0.9929\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0108 - binary_accuracy: 0.9962\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0557 - binary_accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0149 - binary_accuracy: 0.9945\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0111 - binary_accuracy: 0.9962\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0117 - binary_accuracy: 0.9967\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0434 - binary_accuracy: 0.9855\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0201 - binary_accuracy: 0.9912\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0173 - binary_accuracy: 0.9945\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0195 - binary_accuracy: 0.9926\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0081 - binary_accuracy: 0.9974\n",
      "27/27 - 0s - loss: 0.1490 - binary_accuracy: 0.9597\n",
      "[[618  15]\n",
      " [ 19 192]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.9597156643867493\n",
      "teacher_specificity\n",
      "0.976303317535545\n",
      "teacher_sensitivity\n",
      "0.909952606635071\n",
      "teacher_precision\n",
      "0.927536231884058\n",
      "teacher_recall\n",
      "0.909952606635071\n",
      "teacher_frr\n",
      "0.09004739336492891\n",
      "teacher_far\n",
      "0.023696682464454975\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.00016728793369324326),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_11.h5')\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accurate-badge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.7374 - student_loss: 0.5199 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.7676 - student_loss: 0.4689 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.7937 - student_loss: 0.4311 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8161 - student_loss: 0.4037 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8268 - student_loss: 0.3834 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8434 - student_loss: 0.3591 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8522 - student_loss: 0.3415 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8548 - student_loss: 0.3387 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8584 - student_loss: 0.3236 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8622 - student_loss: 0.3126 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8681 - student_loss: 0.3124 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8750 - student_loss: 0.2903 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8740 - student_loss: 0.2946 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8767 - student_loss: 0.2830 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8817 - student_loss: 0.2808 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8862 - student_loss: 0.2759 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8869 - student_loss: 0.2690 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8921 - student_loss: 0.2614 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9009 - student_loss: 0.2407 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8990 - student_loss: 0.2505 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8981 - student_loss: 0.2525 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9002 - student_loss: 0.2420 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8978 - student_loss: 0.2609 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9030 - student_loss: 0.2403 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9099 - student_loss: 0.2261 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9071 - student_loss: 0.2249 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9030 - student_loss: 0.2364 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9090 - student_loss: 0.2263 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9019 - student_loss: 0.2322 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9016 - student_loss: 0.2346 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9076 - student_loss: 0.2317 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9135 - student_loss: 0.2127 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9152 - student_loss: 0.2147 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9116 - student_loss: 0.2134 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9087 - student_loss: 0.2347 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9159 - student_loss: 0.2100 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9123 - student_loss: 0.2093 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9133 - student_loss: 0.2138 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9166 - student_loss: 0.2105 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9163 - student_loss: 0.2070 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9187 - student_loss: 0.2049 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9125 - student_loss: 0.2143 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9118 - student_loss: 0.2206 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9123 - student_loss: 0.2081 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9180 - student_loss: 0.2038 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9183 - student_loss: 0.2014 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9230 - student_loss: 0.1919 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9230 - student_loss: 0.2072 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9211 - student_loss: 0.1945 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9270 - student_loss: 0.1831 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9247 - student_loss: 0.1806 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9190 - student_loss: 0.1948 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9175 - student_loss: 0.1948 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9301 - student_loss: 0.1838 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9218 - student_loss: 0.1826 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9223 - student_loss: 0.1927 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9247 - student_loss: 0.1859 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9342 - student_loss: 0.1778 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9316 - student_loss: 0.1762 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9275 - student_loss: 0.1786 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9327 - student_loss: 0.1732 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9280 - student_loss: 0.1706 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9342 - student_loss: 0.1695 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9308 - student_loss: 0.1776 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9349 - student_loss: 0.1707 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9297 - student_loss: 0.1735 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9361 - student_loss: 0.1652 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9332 - student_loss: 0.1718 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9297 - student_loss: 0.1729 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9325 - student_loss: 0.1721 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9335 - student_loss: 0.1737 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9377 - student_loss: 0.1589 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9437 - student_loss: 0.1486 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9370 - student_loss: 0.1632 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9318 - student_loss: 0.1670 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9396 - student_loss: 0.1510 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9349 - student_loss: 0.1607 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9413 - student_loss: 0.1569 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9434 - student_loss: 0.1468 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9349 - student_loss: 0.1613 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9442 - student_loss: 0.1464 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9449 - student_loss: 0.1453 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9446 - student_loss: 0.1442 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9404 - student_loss: 0.1495 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9411 - student_loss: 0.1503 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9418 - student_loss: 0.1498 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9449 - student_loss: 0.1453 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9472 - student_loss: 0.1360 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9496 - student_loss: 0.1376 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9439 - student_loss: 0.1480 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9430 - student_loss: 0.1408 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9423 - student_loss: 0.1416 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9456 - student_loss: 0.1386 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9432 - student_loss: 0.1467 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9458 - student_loss: 0.1375 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9503 - student_loss: 0.1328 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9506 - student_loss: 0.1294 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9513 - student_loss: 0.1318 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9451 - student_loss: 0.1353 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9496 - student_loss: 0.1277 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.9514 - student_loss: 0.1295\n",
      "[[609  24]\n",
      " [ 17 194]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "0.9514217972755432\n",
      "student_specificity\n",
      "0.9620853080568721\n",
      "student_sensitivity\n",
      "0.919431279620853\n",
      "student_precision\n",
      "0.8899082568807339\n",
      "student_recall\n",
      "0.919431279620853\n",
      "student_frr\n",
      "0.08056872037914692\n",
      "student_far\n",
      "0.037914691943127965\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_11.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "headed-mission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "varying-assembly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmpxl3pkdb0.h5\n",
      "Saved student model to: /tmp/tmp0i6zf6zq.h5\n",
      "Size of gzipped Teacher model: 810529.00 bytes\n",
      "Size of gzipped Student model: 13727.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
