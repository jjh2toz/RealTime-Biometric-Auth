{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excessive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inner-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attempted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "competitive-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 3\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "velvet-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 36, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5994355970980556),\n",
    "        layers.LSTM(245),\n",
    "        layers.Dense(220, activation = 'relu'),\n",
    "        layers.Dense(50, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 16, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 8, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.LSTM(20),\n",
    "        layers.Dense(5, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "renewable-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 480, 32)           224       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 160, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 160, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 53, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 53, 36)            3492      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 17, 36)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 36)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 245)               276360    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 220)               54120     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                11050     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 348,401\n",
      "Trainable params: 348,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.4879 - binary_accuracy: 0.7514\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.3818 - binary_accuracy: 0.8189\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.3403 - binary_accuracy: 0.8472\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.3279 - binary_accuracy: 0.8443\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.3056 - binary_accuracy: 0.8562\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2865 - binary_accuracy: 0.8733\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.2749 - binary_accuracy: 0.8828\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2657 - binary_accuracy: 0.8783\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2567 - binary_accuracy: 0.8888\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2516 - binary_accuracy: 0.8864\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2431 - binary_accuracy: 0.8945\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2304 - binary_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2236 - binary_accuracy: 0.9057\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.2161 - binary_accuracy: 0.9064\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2128 - binary_accuracy: 0.9076\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2073 - binary_accuracy: 0.9095\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.2004 - binary_accuracy: 0.9106\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1917 - binary_accuracy: 0.9206\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1960 - binary_accuracy: 0.9218\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1935 - binary_accuracy: 0.9197\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1944 - binary_accuracy: 0.9194\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1874 - binary_accuracy: 0.9223\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1765 - binary_accuracy: 0.9216\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1887 - binary_accuracy: 0.9211\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1735 - binary_accuracy: 0.9242\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1769 - binary_accuracy: 0.9299\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1786 - binary_accuracy: 0.9232\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1736 - binary_accuracy: 0.9292\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1698 - binary_accuracy: 0.9306\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1693 - binary_accuracy: 0.9304\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1802 - binary_accuracy: 0.9294\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1642 - binary_accuracy: 0.9320\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1529 - binary_accuracy: 0.9375\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1602 - binary_accuracy: 0.9327\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1648 - binary_accuracy: 0.9332\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1612 - binary_accuracy: 0.9385\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1661 - binary_accuracy: 0.9311\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1518 - binary_accuracy: 0.9377\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1550 - binary_accuracy: 0.9358\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1493 - binary_accuracy: 0.9389\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1503 - binary_accuracy: 0.9418\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1481 - binary_accuracy: 0.9363\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1511 - binary_accuracy: 0.9354\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.1480 - binary_accuracy: 0.9385\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 0.1504 - binary_accuracy: 0.9392\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.1422 - binary_accuracy: 0.9437\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.1390 - binary_accuracy: 0.9432\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.1395 - binary_accuracy: 0.9423\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.1348 - binary_accuracy: 0.9451\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.1359 - binary_accuracy: 0.9475\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1419 - binary_accuracy: 0.9399\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.1380 - binary_accuracy: 0.9418\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1346 - binary_accuracy: 0.9427\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.1377 - binary_accuracy: 0.9432\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.1248 - binary_accuracy: 0.9451\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.1266 - binary_accuracy: 0.9489\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.1239 - binary_accuracy: 0.9489\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 0.1249 - binary_accuracy: 0.9494\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 6s 27ms/step - loss: 0.1180 - binary_accuracy: 0.9501\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 0.1233 - binary_accuracy: 0.9468\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 6s 26ms/step - loss: 0.1195 - binary_accuracy: 0.9532\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.1211 - binary_accuracy: 0.9503\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1247 - binary_accuracy: 0.9489\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.1104 - binary_accuracy: 0.9558\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1216 - binary_accuracy: 0.9480\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1165 - binary_accuracy: 0.9532\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1236 - binary_accuracy: 0.9491\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1254 - binary_accuracy: 0.9484\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1086 - binary_accuracy: 0.9556\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.1162 - binary_accuracy: 0.9520\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1129 - binary_accuracy: 0.9553\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1004 - binary_accuracy: 0.9579\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1067 - binary_accuracy: 0.9570\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1037 - binary_accuracy: 0.9587\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.1147 - binary_accuracy: 0.9544\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1049 - binary_accuracy: 0.9577\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1151 - binary_accuracy: 0.9532\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1023 - binary_accuracy: 0.9598\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1034 - binary_accuracy: 0.9582\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1041 - binary_accuracy: 0.9548\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0992 - binary_accuracy: 0.9641\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1082 - binary_accuracy: 0.9591\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0942 - binary_accuracy: 0.9634\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1014 - binary_accuracy: 0.9579\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0904 - binary_accuracy: 0.9658\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0914 - binary_accuracy: 0.9622\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.1048 - binary_accuracy: 0.9589\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0961 - binary_accuracy: 0.9577\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0965 - binary_accuracy: 0.9591\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0874 - binary_accuracy: 0.9651\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0909 - binary_accuracy: 0.9639\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0924 - binary_accuracy: 0.9627\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0979 - binary_accuracy: 0.9587\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0802 - binary_accuracy: 0.9674\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0885 - binary_accuracy: 0.9639\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0835 - binary_accuracy: 0.9679\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0876 - binary_accuracy: 0.9644\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0772 - binary_accuracy: 0.9708\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0875 - binary_accuracy: 0.9674\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0876 - binary_accuracy: 0.9670\n",
      "27/27 - 0s - loss: 0.1454 - binary_accuracy: 0.9502\n",
      "[[615  18]\n",
      " [ 24 187]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.950236976146698\n",
      "teacher_specificity\n",
      "0.9715639810426541\n",
      "teacher_sensitivity\n",
      "0.8862559241706162\n",
      "teacher_precision\n",
      "0.9121951219512195\n",
      "teacher_recall\n",
      "0.8862559241706162\n",
      "teacher_frr\n",
      "0.11374407582938388\n",
      "teacher_far\n",
      "0.02843601895734597\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.00021122153321731643),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_4.h5')\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accurate-badge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.7578 - student_loss: 0.4721 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.8308 - student_loss: 0.3740 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8462 - student_loss: 0.3440 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.8481 - student_loss: 0.3344 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8605 - student_loss: 0.3029 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8617 - student_loss: 0.3009 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8748 - student_loss: 0.2842 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8783 - student_loss: 0.2764 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.8900 - student_loss: 0.2619 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.8881 - student_loss: 0.2591 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8942 - student_loss: 0.2595 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.8971 - student_loss: 0.2409 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.8995 - student_loss: 0.2480 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8995 - student_loss: 0.2425 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9000 - student_loss: 0.2327 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8942 - student_loss: 0.2449 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9026 - student_loss: 0.2353 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8973 - student_loss: 0.2392 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9054 - student_loss: 0.2271 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.8981 - student_loss: 0.2322 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.9135 - student_loss: 0.2145 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.9068 - student_loss: 0.2248 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9057 - student_loss: 0.2310 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9004 - student_loss: 0.2366 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.9111 - student_loss: 0.2159 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.9009 - student_loss: 0.2352 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9085 - student_loss: 0.2155 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9118 - student_loss: 0.2167 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9106 - student_loss: 0.2151 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9128 - student_loss: 0.2155 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9099 - student_loss: 0.2184 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9102 - student_loss: 0.2076 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9095 - student_loss: 0.2113 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.9118 - student_loss: 0.2155 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9114 - student_loss: 0.2069 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9073 - student_loss: 0.2202 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9137 - student_loss: 0.2087 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9152 - student_loss: 0.2052 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.9163 - student_loss: 0.2005 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9159 - student_loss: 0.2130 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 5s 23ms/step - binary_accuracy: 0.9178 - student_loss: 0.2012 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.9199 - student_loss: 0.2001 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9230 - student_loss: 0.1982 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9159 - student_loss: 0.2003 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9140 - student_loss: 0.2053 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9116 - student_loss: 0.2058 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9192 - student_loss: 0.1925 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9144 - student_loss: 0.2043 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9144 - student_loss: 0.1988 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9221 - student_loss: 0.1903 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9204 - student_loss: 0.1967 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9190 - student_loss: 0.1991 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9211 - student_loss: 0.1968 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9130 - student_loss: 0.1979 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9197 - student_loss: 0.1908 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9202 - student_loss: 0.1930 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9225 - student_loss: 0.1891 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9163 - student_loss: 0.1937 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9237 - student_loss: 0.1898 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9206 - student_loss: 0.1967 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9197 - student_loss: 0.1928 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9225 - student_loss: 0.1873 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9142 - student_loss: 0.1962 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9289 - student_loss: 0.1787 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9254 - student_loss: 0.1807 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9266 - student_loss: 0.1880 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9266 - student_loss: 0.1853 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9159 - student_loss: 0.1941 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9204 - student_loss: 0.1888 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9204 - student_loss: 0.1842 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9185 - student_loss: 0.1905 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9230 - student_loss: 0.1808 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9228 - student_loss: 0.1811 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9190 - student_loss: 0.1898 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9199 - student_loss: 0.1870 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9235 - student_loss: 0.1871 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9221 - student_loss: 0.1869 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9194 - student_loss: 0.1877 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9244 - student_loss: 0.1789 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9163 - student_loss: 0.1978 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9259 - student_loss: 0.1805 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9280 - student_loss: 0.1738 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9216 - student_loss: 0.1890 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9225 - student_loss: 0.1838 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9263 - student_loss: 0.1786 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9240 - student_loss: 0.1792 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9221 - student_loss: 0.1871 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9230 - student_loss: 0.1850 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9244 - student_loss: 0.1738 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9266 - student_loss: 0.1764 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9304 - student_loss: 0.1702 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9301 - student_loss: 0.1703 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9273 - student_loss: 0.1719 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9297 - student_loss: 0.1759 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9318 - student_loss: 0.1636 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9289 - student_loss: 0.1720 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9268 - student_loss: 0.1797 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9306 - student_loss: 0.1738 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9254 - student_loss: 0.1850 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9225 - student_loss: 0.1781 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.9491 - student_loss: 0.1313\n",
      "[[610  23]\n",
      " [ 20 191]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "0.9490521550178528\n",
      "student_specificity\n",
      "0.9636650868878357\n",
      "student_sensitivity\n",
      "0.9052132701421801\n",
      "student_precision\n",
      "0.8925233644859814\n",
      "student_recall\n",
      "0.9052132701421801\n",
      "student_frr\n",
      "0.0947867298578199\n",
      "student_far\n",
      "0.036334913112164295\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_4.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "headed-mission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prospective-mileage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmprrwpul6m.h5\n",
      "Saved student model to: /tmp/tmpx5mr8l4v.h5\n",
      "Size of gzipped Teacher model: 1296586.00 bytes\n",
      "Size of gzipped Student model: 13746.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
