{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "excessive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "inner-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "attempted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "competitive-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 6\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "velvet-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 44, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 30, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 18, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.27033619412910087),\n",
    "        layers.LSTM(34),\n",
    "        layers.Dense(14, activation = 'relu'),\n",
    "        layers.Dense(115, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 22, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 15, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 9, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.LSTM(15),\n",
    "        layers.Dense(7, activation = 'relu'),\n",
    "        layers.Dense(55, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "renewable-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 480, 44)           308       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 160, 44)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 160, 30)           3990      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 53, 30)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 53, 18)            1638      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 17, 18)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 17, 18)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 34)                7208      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 14)                490       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 115)               1725      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 116       \n",
      "=================================================================\n",
      "Total params: 15,475\n",
      "Trainable params: 15,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.5256 - binary_accuracy: 0.7457\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.4521 - binary_accuracy: 0.7845\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 0.3945 - binary_accuracy: 0.8265\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 0.3576 - binary_accuracy: 0.8517\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.3277 - binary_accuracy: 0.8638\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.3117 - binary_accuracy: 0.8712\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2945 - binary_accuracy: 0.8812\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2961 - binary_accuracy: 0.8793\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2780 - binary_accuracy: 0.8840\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2607 - binary_accuracy: 0.8933\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2569 - binary_accuracy: 0.8942\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2442 - binary_accuracy: 0.9023\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2439 - binary_accuracy: 0.9011\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2458 - binary_accuracy: 0.8952\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2333 - binary_accuracy: 0.8997\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 0.2393 - binary_accuracy: 0.9016\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.2302 - binary_accuracy: 0.9047\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 0.2243 - binary_accuracy: 0.9052\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 0.2100 - binary_accuracy: 0.9159\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 0.2150 - binary_accuracy: 0.9116\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.2163 - binary_accuracy: 0.9092\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.2061 - binary_accuracy: 0.9187\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.2047 - binary_accuracy: 0.9185\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 0.2025 - binary_accuracy: 0.9095\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 0.1987 - binary_accuracy: 0.9187\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1987 - binary_accuracy: 0.9140\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1857 - binary_accuracy: 0.9242\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1835 - binary_accuracy: 0.9254\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1880 - binary_accuracy: 0.9240\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1746 - binary_accuracy: 0.9287\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1805 - binary_accuracy: 0.9259\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1758 - binary_accuracy: 0.9270\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1720 - binary_accuracy: 0.9278\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1698 - binary_accuracy: 0.9280\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1552 - binary_accuracy: 0.9342\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1574 - binary_accuracy: 0.9349\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1500 - binary_accuracy: 0.9389\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1489 - binary_accuracy: 0.9396\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1507 - binary_accuracy: 0.9404\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1549 - binary_accuracy: 0.9411\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1481 - binary_accuracy: 0.9365\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1477 - binary_accuracy: 0.9396\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1391 - binary_accuracy: 0.9451\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1390 - binary_accuracy: 0.9463\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1337 - binary_accuracy: 0.9465\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1324 - binary_accuracy: 0.9420\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1367 - binary_accuracy: 0.9420\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1351 - binary_accuracy: 0.9468\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1209 - binary_accuracy: 0.9510\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1162 - binary_accuracy: 0.9546\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1151 - binary_accuracy: 0.9518\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1226 - binary_accuracy: 0.9527\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9529\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1272 - binary_accuracy: 0.9499\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1160 - binary_accuracy: 0.9544\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1106 - binary_accuracy: 0.9548\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1145 - binary_accuracy: 0.9572\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1010 - binary_accuracy: 0.9591\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1068 - binary_accuracy: 0.9565\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0964 - binary_accuracy: 0.9620\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1007 - binary_accuracy: 0.9589\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1022 - binary_accuracy: 0.9591\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0929 - binary_accuracy: 0.9632\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0991 - binary_accuracy: 0.9591\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0893 - binary_accuracy: 0.9632\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0856 - binary_accuracy: 0.9672\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1052 - binary_accuracy: 0.9582\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0945 - binary_accuracy: 0.9620\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0947 - binary_accuracy: 0.9596\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0846 - binary_accuracy: 0.9696\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0827 - binary_accuracy: 0.9670\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0935 - binary_accuracy: 0.9620\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0801 - binary_accuracy: 0.9684\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0913 - binary_accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0913 - binary_accuracy: 0.9655\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0816 - binary_accuracy: 0.9682\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0729 - binary_accuracy: 0.9715\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0877 - binary_accuracy: 0.9644\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0835 - binary_accuracy: 0.9672\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0740 - binary_accuracy: 0.9729\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0833 - binary_accuracy: 0.9691\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0732 - binary_accuracy: 0.9682\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0833 - binary_accuracy: 0.9691\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0679 - binary_accuracy: 0.9755\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0749 - binary_accuracy: 0.9720\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0826 - binary_accuracy: 0.9693\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0641 - binary_accuracy: 0.9772\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0669 - binary_accuracy: 0.9729\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0748 - binary_accuracy: 0.9724\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0674 - binary_accuracy: 0.9753\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0854 - binary_accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0560 - binary_accuracy: 0.9774\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0591 - binary_accuracy: 0.9772\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0696 - binary_accuracy: 0.9736\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0555 - binary_accuracy: 0.9796\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0612 - binary_accuracy: 0.9774\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0679 - binary_accuracy: 0.9729\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0602 - binary_accuracy: 0.9774\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.0678 - binary_accuracy: 0.9734\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0715 - binary_accuracy: 0.9743\n",
      "27/27 - 0s - loss: 0.4585 - binary_accuracy: 0.8495\n",
      "[[578  55]\n",
      " [ 72 139]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAG5CAYAAACnXrwnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAh0klEQVR4nO3de7gedXXo8e/KBQIEEnIRIQkEjyktWgweiCjUglAlVBvqgwi1iJ7UlIpUvEJL691zpBUFlaIoSLCCqBiJFAXLRfDGRUUMYiUCaRIDIVcgXEL2XuePd3Z4ocm+JO9lz8z38zzzZOY388783s1+WHut+c1vIjORJEnlMaLbHZAkSUNj8JYkqWQM3pIklYzBW5KkkjF4S5JUMgZvSZJKxuAtaUAR8UBEHDWI46ZHREbEqE70S6org7dKJSL+KiLuiIjHImJFRHw3Ig4r9n2oCBzHNx0/qmibXmxfUmzPajrmhREx5AkPIuKmiPibreybGxG/iYhHI+KhiLgmInYt+vtYsTwdERubtj8fEYcX/VvwnPO9pGi/aaj9lFQ9Bm+VRkS8GzgX+L/AHsDewL8Bc5oOWwN8OCJG9nOqNcDHBnnNt0TEJUPs558WfTwxM3cF/gi4AiAzZ2fm2MwcC3wV+Je+7cw8pTjFw8DLI2Ji02lPBn47lH5Iqi6Dt0ohIsYBHwFOzcxvZeaGzHw6M7+Tme9rOvR7wEbgr/s53XzggCLItsPBwE8y8xcAmbkmM+dn5qOD/PxG4NvACQDFHyJvpBHst6ipXP3WiFgaEWsj4pSIODgi7oqIdRHxuabjR0TEP0XEkohYGRGXFj/jvv0nFftWR8RZz7nWiIg4MyJ+V+z/ekRMGOR3k9QCBm+VxcuBMcCCAY5L4J+BD0bE6K0c8ziNzPjjreves9wKvCYiPhwRh0bEjttwjkuBNxfrrwEWAb8fxOdeBsygEezPBc4CjgJeBBzf9AfLW4rlCOAFwFjgcwARsT9wAXASsBcwEZjadI3TgGOBPy32rwXOH+L3k7QdDN4qi4nAqszcNNCBmbmQRul5i/ejC18A9o6I2S3qX/P1bwFeD7wU+A9gdUR8aoBS/nPP8WNgQkTsRyOIXzrIj340M5/MzOuADcDlmbkyM5cDtwAHFse9CfhUZt6XmY8B/wCcUAw0Ow64OjNvzsynaPwx1Nt0jVOAszJzWbH/Q8BxDlKTOsfgrbJYDUwaQoD4JxpZ55gt7SyCzkeL5Vki4t+KMvM6GvfU/6pvOyLuGszFM/O7mfk6YAKNe/Jvof8/JrbkK8A7aGTHA1Uc+jzUtP7EFrbHFut7AUua9i0BRtEYS7AXsLRvR2ZuoPHz77MPsKDpZ3QP0FN8VlIHGLxVFj8BnqJRrh1QZn4fWAy8vZ/DvgyMp5ElN3/27Zk5PjPHF5+/rG87Mw8YSqczszczrwduAF48lM/SCN5vB67JzMeH+NmB/J5GEO6zN7CJRrBfAUzr2xERO9OofPRZCsxu+pmMz8wxRXYvqQMM3iqFzFwPfAA4PyKOjYidI2J0RMyOiH/ZysfOAt7fzzk3AR8EztiOro2KiDFNy+iImBMRJ0TE7tEwi8b94Z8O5cSZeX/xubMGOnYbXA68KyL2jYixNMYAXFH8TL4JvDYiDouIHWgMFGz+f8XngY9HxD4AETE5IuYgqWMM3iqNzDwHeDeNkvjDNDLAd9AYmb2l438E3DbAaS+nkWluqwtolKP7li/TGMD1NuBe4BHg34F/zcytjhbfmsz8YWYOZqDaUF1MI7O/GbgfeJLGQDQy827gVOAyGj+btcCyps+eBywErouIR2n8UfKyNvRR0lZE5pDnppAkSV1k5i1JUskYvCVJKhmDtyRJJWPwliSpZAzekiSVjMG75iLi6Ij4r4hYHBFndrs/UidExMXFC1kWdbsv0rYweNdYMdf2+cBsYH/gxOKlFFLVXQIc3e1OSNvK4F1vs4DFxcspNgJf49nvxpYqKTNvpvFed6mUDN71NoWmF1DQmEVrSpf6IkkaJIO3JEklY/Cut+U0vT0KmFq0SZKGMYN3vd0OzCjeLLUDcAKNF05IkoYxg3eNFa9/fAdwLXAP8PXijVJSpUXE5TTeEb9fRCyLiLnd7pM0FL5VTJKkkjHzliSpZAzekiSVjMFbkqSSMXhLklQyBm8BEBHzut0HqdP8vVdZGbzVx/+JqY78vVcpGbwlSSqZYfWc96QJI3P6tNHd7kYtPby6h8kTR3a7G7X027t27nYXautpnmI0O3a7G7X0JBvYmE9Fp673miN2ydVrelpyrp/d9dS1mdnVV8qO6ubFn2v6tNHcdu20gQ+UKuQ1e83sdhekjrs1r+/o9Vav6eG2a/duyblG7nnvpJacaDsMq+AtSVI7JNBLb7e70TLe85YkqWTMvCVJNZD0ZHUyb4O3JKnyGmXz4TNAe3tZNpckqWTMvCVJtVClAWsGb0lS5SVJzzCa12R7WTaXJKlkzLwlSbVQpQFrBm9JUuUl0FOh4G3ZXJKkkjHzliTVgmVzSZJKJMHR5pIkqXvMvCVJtVCdKVoM3pKkGkjS0eaSJKl7zLwlSdWX0FOdxNvgLUmqvsYrQavDsrkkSSVj5i1JqoGgh+h2J1rG4C1JqrwEeit0z9uyuSRJJWPmLUmqBcvmkiSVSOOVoNUJ3pbNJUkqGTNvSVIt9GZ1Mm+DtySp8iybS5KkrjLzliRVXhL0VChfNXhLkmrBe96SJJWI97wlSVJXmXlLkmog6Mnq5KsGb0lS5TXe512d4F2dbyJJUk2YeUuSaqFKA9YM3pKkysus1j3v6nwTSZJqwsxbklQLvZbNJUkqj8YkLdUpNlfnm0iSVBNm3pKkGqjWgDWDtySp8pykRZIkdZWZtySpFnp8JagkSeWRhKPNJUlS95h5S5JqodfR5pIklYeTtEiSpK4y85YkVV4SjjaXJKlsOjlJS0Q8ADwK9ACbMvOgiJgAXAFMBx4Ajs/MtRERwHnAMcDjwFsy8+f9nd+yuSRJ7XFEZs7MzIOK7TOB6zNzBnB9sQ0wG5hRLPOACwY6sZm3JKnyMhkOc5vPAQ4v1ucDNwFnFO2XZmYCP42I8RGxZ2au2NqJuv5NJElqv6C3RQswKSLuaFrmbeGCCVwXET9r2r9HU0B+ENijWJ8CLG367LKibavMvCVJGppVTaXwrTksM5dHxPOA70fEb5p3ZmZGRG5rBwzekqTKSzpbNs/M5cW/KyNiATALeKivHB4RewIri8OXA9OaPj61aNsqy+aSpFroYURLloFExC4RsWvfOvBqYBGwEDi5OOxk4KpifSHw5mg4BFjf3/1uMPOWJKnV9gAWNJ4AYxRwWWZ+LyJuB74eEXOBJcDxxfHX0HhMbDGNR8XeOtAFDN6SpMpLgt4OTdKSmfcBL9lC+2rgyC20J3DqUK5h8JYk1YJzm0uSpK4x85YkVV7iK0ElSSqZoIfqvJikOn+GSJJUE2bekqTKs2wuSVIJWTaXJEldY+YtSaq8zLBsLklS2QyD93m3THW+iSRJNWHmLUmqvAR6KzRgzeAtSaqBsGwuSZK6x8xbklR5jUlaLJtLklQqvhJUkiR1jZm3JKnykrBsLklS2fRWqNhcnW8iSVJNmHlLkiovE3osm0uSVC5Vuudt2VySpJIx85YkVV5jtHl18lWDtySpFnp8MYmqKibfCL0bgF5gE7n69cS4c2HUCxoHjNgVeh8lV/8FMIoY93EY9SKIUeQTC2DDF7rXeWkbfeW+83ni0Sfp7emlZ1MPp846k5M++AaO+ZujWP/wIwBcfNZl3PbdX3S5p9pWTo+qyss1J0GufWZ7/emb12PXM8nexxobY2YDO5CrXwuMISZ/l3zyauhZ3tH+Sq3w3ld9iEdWP/qstivPvZpvnvOd7nRI6ofBW0Mz5hhYc1KxkRA7AyMhxkA+DX2BXZKGlWrd867ON1FrZBITvkxMXAA7vfHZ+0YfDL2roGdJY/vJ70E+Tjzvx8TkH5AbLoJc3/k+S9spEz5x7T9x/u1nc8zbjtrcPufUo/nCnZ/kPRf9HWPH79LFHqoVeomWLMNBWzPviDgaOA8YCXwpMz/Rzutp++WaE6H3IRgxgdj9EnLTffD07QDETq8ln7j6mYNHHwD0kisPhRG7ERMuJzf+GHqWdqfz0jZ615/8M6t/v4bxk3fjE9f9M0t/s5zvXHAdX/3olWQmb/noCfztOW/mnLkXdLurEtDGzDsiRgLnA7OB/YETI2L/dl1PLdL7UPHvGnjq+0WABhgJO74anrxm86Ex5nXkUzcDmxrHb/w5jH5xx7ssba/Vv18DwLqHH+FH376N/Wa9kHUr19Pb20tmcs0X/5P9Dn5hl3up7dE3w1orluGgnWXzWcDizLwvMzcCXwPmtPF62l6xE8Quz6zvcBhs+m1je4dXQM990Pvg5sOzdwWxw8ubjp8Jm+7rbJ+l7TRm5x3ZaeyYzev/+89ewgOLljLh+eM3H3PoX87igUVWlMquN0e0ZBkO2lk2nwI0/7YvA1723IMiYh4wD2DvKY6f66oRk4jx5xcbo8gnvwMbbwG2UDIHePzfYdwniInXQAT5+JWw6b8622dpO43fYxwf+tb7ABg5aiQ3Xv5D7rj2Ts6Yfxr/a+Z0MpOHHniYc0/xMUgNH12Plpl5IXAhwEEvGZNd7k699Swtnt/+n3L9GVtofJxc9/dt7pTUXg/ev5JTDnzf/2g/++TPdqE3ahff5z14y4FpTdtTizZJkjpuuIwUb4V2Fu9vB2ZExL4RsQNwArCwjdeTJKkW2pZ5Z+amiHgHcC2NR8Uuzsy723U9SZK2xulRhyAzrwGuGfBASZLabLiMFG+F6nwTSZJqouujzSVJart0tLkkSaWSONpckiR1kZm3JKkWLJtLklQiVXtUzLK5JEklY+YtSaqFKmXeBm9JUuVV7cUkls0lSSoZM29JUi1U6Tlvg7ckqfqyWve8LZtLklQyZt6SpMqr2nPeBm9JUi1UKXhbNpckqWTMvCVJlVe157wN3pKkWsgKBW/L5pIklYyZtySpFpykRZKkEkknaZEkSd1k5i1JqoUqDVgzeEuSaqBaj4pZNpckqWTMvCVJtVClsrmZtySp8vpeTNKKZTAiYmRE/CIiri62942IWyNicURcERE7FO07FtuLi/3TB3N+g7ckSa33TuCepu2zgU9n5guBtcDcon0usLZo/3Rx3IAM3pKk6svGs96tWAYSEVOBPwe+VGwH8Crgm8Uh84Fji/U5xTbF/iOL4/vlPW9JUi20cIa1SRFxR9P2hZl5YdP2ucD7gV2L7YnAuszcVGwvA6YU61OApQCZuSki1hfHr+qvAwZvSZKGZlVmHrSlHRHxWmBlZv4sIg5vVwcM3pKkyks6Ntr8UOAvIuIYYAywG3AeMD4iRhXZ91RgeXH8cmAasCwiRgHjgNUDXcR73pKkGmjNSPOBRptn5j9k5tTMnA6cANyQmW8CbgSOKw47GbiqWF9YbFPsvyFz4DvrBm9JktrvDODdEbGYxj3ti4r2i4CJRfu7gTMHczLL5pKkWhjMSPHWXi9vAm4q1u8DZm3hmCeBNwz13AZvSVItOMOaJEnqGjNvSVLlNSZYqU7mbfCWJNWCrwSVJEldY+YtSaqFTo82byeDtySpFrznLUlSiSRRqeDtPW9JkkrGzFuSVAsVuuVt8JYk1UDFnvO2bC5JUsmYeUuS6qFCdXODtySpFiybS5KkrjHzliTVgjOsSZJUIollc0mS1EVm3pKk6kugQpm3wVuSVAtVuudt2VySpJIx85Yk1UOFMm+DtySpBnwlqCRJ6iIzb0lSPVg2lySpRHwlqCRJ6iYzb0lSPVg2lySpbCybS5KkLjHzliTVg2VzSZJKpkLB27K5JEklY+YtSao+XwkqSVL5+EpQSZLUNWbekqR6qFDmbfCWJNVDhe55WzaXJKlkzLwlSbUQls0lSSqRpFL3vC2bS5JUMlvNvCPis/Tzd0pm/n1beiRJUstFpQas9Vc2v6NjvZAkqd0qVDbfavDOzPmd7IgkSRqcAQesRcRk4Axgf2BMX3tmvqqN/ZIkqbUqlHkPZsDaV4F7gH2BDwMPALe3sU+SJLVetmgZBgYTvCdm5kXA05n5g8z8P4BZtyRJXTKY57yfLv5dERF/DvwemNC+LkmS1GI1fCXoxyJiHPAe4LPAbsC72torSZJarFYzrGXm1cXqeuCI9nZHkiQNZDCjzb/MFm7RF/e+JUkqhzpl3sDVTetjgL+kcd9bkiR1wWDK5lc2b0fE5cAP29YjSZLUr215q9gM4Hmt7gjAvYvGMnvGoe04tTR8zXpBt3sgdd6iH3f8krUasBYRj/LsOwUP0phxTZKk8qjTo2KZuWsnOiJJkgZnwBnWIuL6wbRJkjRstWpq1GFSeu/vfd5jgJ2BSRGxO9BXb9gNmNKBvkmS1DrDJPC2Qn9l878FTgf2An7GM8H7EeBz7e2WJEmtVYsBa5l5HnBeRJyWmZ/tYJ8kSVI/BvNWsd6IGN+3ERG7R8Tb29clSZLaoEL3vAcTvN+Wmev6NjJzLfC2tvVIkqR2qFnwHhkRmx+Oi4iRwA7t65IkSeUVEWMi4raI+GVE3B0RHy7a942IWyNicURcERE7FO07FtuLi/3TB7rGYIL394ArIuLIiDgSuBz47nZ8L0mSOiqydcsgPAW8KjNfAswEjo6IQ4CzgU9n5guBtcDc4vi5wNqi/dPFcf0aTPA+A7gBOKVYfgXsNKjuS5I0XGS0ZhnoMg2PFZujiyWBVwHfLNrnA8cW63OKbYr9RzZXvLdkwOCdmb3ArcADwKzi4vcM2HtJkmoqIkZGxJ3ASuD7wO+AdZm5qThkGc/MmTIFWApQ7F8PTOzv/P1N0vIHwInFsgq4ojjxEdv4XSRJ6p7WDTabFBF3NG1fmJkXPutSmT3AzOJprQXAH7bs6vQ/SctvgFuA12bmYoCIeFcrLy5JUqe0cJKWVZl50GAOzMx1EXEj8HJgfESMKrLrqcDy4rDlwDRgWUSMAsYBq/s7b39l89cDK4AbI+KLxWC16rySRZKkNoiIyX3zo0TETsCf0bjdfCNwXHHYycBVxfrCYpti/w2Z2e+fGv3NsPZt4NsRsQuNm+mnA8+LiAuABZl53dC/kiRJXdK5Z7T3BOYXj1aPAL6emVdHxK+Br0XEx4BfABcVx18EfCUiFgNrgBMGusBgXgm6AbgMuKx4QckbaIxAN3hLksph8I95bf+lMu8CDtxC+300Bn4/t/1JGrF10AbzqFjzBdZm5oWZeeRQPidJklpnwMxbkqRKGCZTm7aCwVuSVA8VCt5DKptLkqTuM/OWJNVCpwasdYKZtyRJJWPwliSpZCybS5LqoUJlc4O3JKn6OjhJSydYNpckqWTMvCVJ9VChzNvgLUmqhwoFb8vmkiSVjJm3JKnygmoNWDN4S5LqoULB27K5JEklY+YtSaq+ij3nbfCWJNVDhYK3ZXNJkkrGzFuSVA8VyrwN3pKkWqjSPW/L5pIklYyZtySpHiqUeRu8JUnVl1QqeFs2lySpZMy8JUm1UKUBawZvSVI9VCh4WzaXJKlkzLwlSbVg2VySpLKpUPC2bC5JUsmYeUuSqq9iz3kbvCVJlRfFUhWWzSVJKhkzb0lSPVg2lySpXKr0qJhlc0mSSsbMW5JUDxXKvA3ekqR6qFDwtmwuSVLJmHlLkqovqzVgzeAtSaoHg7ckSeVSpczbe96SJJWMmbckqR4qlHkbvCVJtWDZXJIkdY2ZtySp+nyftyRJJVSh4G3ZXJKkkjHzliRVXlCtAWsGb0lSPVQoeFs2lySpZMy8JUm1EFmd1NvgLUmqvoo9KmbZXJKkkjHzliTVgqPNJUkqmwoFb8vmkiSVjJm3JKkWLJtLklQ2FQrels0lSSoZM29JUvWlZXNJksqnQsHbsrkkSS0UEdMi4saI+HVE3B0R7yzaJ0TE9yPi3uLf3Yv2iIjPRMTiiLgrIl460DUM3pKkyut7JWgrlkHYBLwnM/cHDgFOjYj9gTOB6zNzBnB9sQ0wG5hRLPOACwa6gMFbklQPma1ZBrxMrsjMnxfrjwL3AFOAOcD84rD5wLHF+hzg0mz4KTA+Ivbs7xoGb0mShmZSRNzRtMzb2oERMR04ELgV2CMzVxS7HgT2KNanAEubPrasaNsqB6xJkmqhhaPNV2XmQQNeL2IscCVwemY+EhGb92VmRmx7j8y8JUnVly1cBiEiRtMI3F/NzG8VzQ/1lcOLf1cW7cuBaU0fn1q0bZXBW5KkFopGin0RcE9mfqpp10Lg5GL9ZOCqpvY3F6PODwHWN5XXt8iyuTabOuP5/OMlb9+8/fzpk/nKxxcwca/dOWT2TJ7euIkV96/knL+7iA3rH+9iT6XWec9Zr+Nlh/4B69ZuYN6bPg/AyfMO5xWv3I/sTdat3cC/fvQqVq96jLG7juE9Z/0Fe03dnY1PbeKcjy/kgfse7vI30GBFb8cudShwEvCriLizaPtH4BPA1yNiLrAEOL7Ydw1wDLAYeBx460AXiBzEyLlOGTdyUh6y82u73Q0BI0YEX/3tubzziI8wdcbzufMH99Db08vcj7wBgIs+8I0u97A6el/0gm53odb+eObePPHERt7/gWM3B++dd96Bxx/fCMCxx89in+mTOO9fruFt7ziKJ57YyL9fdDPT9pnIae89hvef9pVudr+0bl30BR55bHkMfGRrjJ0wLQ846vSWnOsn33jvzwZzz7udLJtri2Yevj8r7l/JyqWr+fkNd9Pb0/iT9Z7bf8ekvSZ0uXdS6/zqzv/m0UeeeFZbX+AGGDNm9ObbnPvsO5k773gAgKVLVrPHnuMYP2GXDvVUeoZlc23R4ce9jJu+8dP/0f6ak17JD668tQs9kjrrraccwVGzD2DDY0/xvlMvBeC+ex/isMP/kEW//G/2238v9nj+eCZP3o11azZ0ubcajCrNbd62zDsiLo6IlRGxqF3XUHuMGj2SQ445kJsX3P6s9hPf+zp6NvVwwxU/6VLPpM758udv5E1zzuOGa3/FnOMOBuBrl/6QsbuO4fOXzuPYN8xi8W9X0NvbuRup2g5JxyZp6YR2ls0vAY5u4/nVJge/+gAW37mEdQ8/srntz950GLNmv4Sz536hiz2TOu/6a3/FYUf8EdAop3/yYws55c0XcvaHv8243XdhxfK1Xe6h6qhtwTszbwbWtOv8ap/DjzuEm775TMn8oKP+mDecPpsPvfE8nnpiYz+flKphyrRnxnW84pX7sXTJKgB2Gbsjo0Y1/rc5e86B/OoXS551f1zDWwfnNm+7rt/zLqaVmwcwJhz40W077rwDL33VizjvnZdsbjv1k3/N6B1H8f+ueh8Av7n9d3zm9PlbOYNULv/4kddzwEv3Ydz4nbls4elc+sWbmPWKGUzdeyKZyUMPrue8s/8DgL2nT+b9H5hDZrLk/oc55+Pf6XLvNSTDJPC2QlsfFSvmdL06M188mON9VEx15KNiqqOOPyq2+7ScecQ7W3KuHy14X9cfFet65i1JUrv1vRK0KgzekqTqG0YjxVuhnY+KXQ78BNgvIpYV08FJkqTt1LbMOzNPbNe5JUkaKsvmkiSVTYWCt3ObS5JUMmbekqRasGwuSVKZJNBbneht2VySpJIx85Yk1UN1Em+DtySpHqp0z9uyuSRJJWPmLUmqhwpNj2rwliTVgmVzSZLUNWbekqTqSxxtLklSmTTe512d6G3wliTVQ2+3O9A63vOWJKlkzLwlSbVg2VySpDKp2IA1y+aSJJWMmbckqQbSGdYkSSobZ1iTJEldY+YtSaoHy+aSJJVIQjhJiyRJ6hYzb0lSPVg2lySpZKoTuy2bS5JUNmbekqRacG5zSZLKpkLB27K5JEklY+YtSaq+BCr0nLfBW5JUeUFW6p63ZXNJkkrGzFuSVA8VyrwN3pKkeqhQ8LZsLklSyZh5S5Kqz9HmkiSVj6PNJUlS15h5S5LqoUKZt8FbklQDWangbdlckqSSMfOWJFVfUqnM2+AtSaqHCj0qZtlckqSSMfOWJNVClZ7zNnhLkuqhQsHbsrkkSSVj5i1Jqr4EequTeRu8JUk14CQtkiSpi8y8JUn1UKHM2+AtSaqHCgVvy+aSJLVQRFwcESsjYlFT24SI+H5E3Fv8u3vRHhHxmYhYHBF3RcRLB3MNg7ckqfr6Rpu3YhnYJcDRz2k7E7g+M2cA1xfbALOBGcUyD7hgMBcweEuSaiAhe1uzDHSlzJuBNc9pngPML9bnA8c2tV+aDT8FxkfEngNdw+AtSdLQTIqIO5qWeYP4zB6ZuaJYfxDYo1ifAixtOm5Z0dYvB6xJkuqhdQPWVmXmQdvejcyI2K7OGLwlSdXX/RnWHoqIPTNzRVEWX1m0LwemNR03tWjrl2VzSZLabyFwcrF+MnBVU/ubi1HnhwDrm8rrW2XmLUmqhw495x0RlwOH07g3vgz4IPAJ4OsRMRdYAhxfHH4NcAywGHgceOtgrmHwliTVQ4eCd2aeuJVdR27h2AROHeo1LJtLklQyZt6SpBqo1lvFDN6SpOpLoHfgCVbKwrK5JEklY+YtSaoHy+aSJJWMwVuSpDIZ9BvBSsF73pIklYyZtySp+hJyEK/zLAuDtySpHiybS5KkbjHzliTVg6PNJUkqkUxnWJMkSd1j5i1JqgfL5pIklUtaNpckSd1i5i1JqgHf5y1JUrkkTtIiSZK6x8xbklQPzm0uSVJ5JJCWzSVJUreYeUuSqi/TsrkkSWVj2VySJHWNmbckqR4qVDaPHEYzzkTEw8CSbvejpiYBq7rdCanD/L3vnn0yc3KnLhYR36Px37sVVmXm0S061zYZVsFb3RMRd2TmQd3uh9RJ/t6rrLznLUlSyRi8JUkqGYO3+lzY7Q5IXeDvvUrJ4C0AMtP/ifUjInoi4s6IWBQR34iInbfjXJdExHHF+pciYv9+jj08Il6xDdd4ICJaNTinsvy9V1kZvKXBeSIzZ2bmi4GNwCnNOyNimx67zMy/ycxf93PI4cCQg7ekajN4S0N3C/DCIiu+JSIWAr+OiJER8a8RcXtE3BURfwsQDZ+LiP+KiP8Entd3ooi4KSIOKtaPjoifR8QvI+L6iJhO44+EdxVZ/59ExOSIuLK4xu0RcWjx2YkRcV1E3B0RXwKiwz8TSR3kJC3SEBQZ9mzge0XTS4EXZ+b9ETEPWJ+ZB0fEjsCPIuI64EBgP2B/YA/g18DFzznvZOCLwCuLc03IzDUR8Xngscz8ZHHcZcCnM/OHEbE3cC3wR8AHgR9m5kci4s+BuW39QUjqKoO3NDg7RcSdxfotwEU0ytm3Zeb9RfurgQP67mcD44AZwCuByzOzB/h9RNywhfMfAtzcd67MXLOVfhwF7B+xObHeLSLGFtd4ffHZ/4iItdv2NSWVgcFbGpwnMnNmc0MRQDc0NwGnZea1zznumBb2YwRwSGY+uYW+SKoJ73lLrXMt8HcRMRogIv4gInYBbgbeWNwT3xM4Yguf/SnwyojYt/jshKL9UWDXpuOuA07r24iImcXqzcBfFW2zgd1b9aUkDT8Gb6l1vkTjfvbPI2IR8AUa1a0FwL3FvkuBnzz3g5n5MDAP+FZE/BK4otj1HeAv+wasAX8PHFQMiPs1z4x6/zCN4H83jfL5f7fpO0oaBpzbXJKkkjHzliSpZAzekiSVjMFbkqSSMXhLklQyBm9JkkrG4C1JUskYvCVJKpn/D/F6UiB1NVDfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.849526047706604\n",
      "teacher_specificity\n",
      "0.9131121642969984\n",
      "teacher_sensitivity\n",
      "0.6587677725118484\n",
      "teacher_precision\n",
      "0.7164948453608248\n",
      "teacher_recall\n",
      "0.6587677725118484\n",
      "teacher_frr\n",
      "0.3412322274881517\n",
      "teacher_far\n",
      "0.08688783570300158\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0007916132524188809),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_7.h5')\n",
    "  \n",
    "# EarlyStopping 조기종료 및 모델 학습\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 20)\n",
    "check_point = MyModelCheckpoint('best_model_' + str(sub_num + 1) + '.h5', monitor = 'val_loss', mode = 'min', save_best_only = True, verbose = 1)\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "accurate-badge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.7500 - student_loss: 0.5310 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.7835 - student_loss: 0.4673 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.7994 - student_loss: 0.4418 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8154 - student_loss: 0.4096 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8258 - student_loss: 0.3867 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8310 - student_loss: 0.3796 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8403 - student_loss: 0.3631 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8394 - student_loss: 0.3602 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8439 - student_loss: 0.3483 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8441 - student_loss: 0.3507 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8491 - student_loss: 0.3357 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8500 - student_loss: 0.3345 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8543 - student_loss: 0.3319 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8560 - student_loss: 0.3247 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8529 - student_loss: 0.3209 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8631 - student_loss: 0.3062 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8588 - student_loss: 0.3048 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8693 - student_loss: 0.3068 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8622 - student_loss: 0.3052 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8662 - student_loss: 0.2993 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8731 - student_loss: 0.2954 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8686 - student_loss: 0.3059 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8757 - student_loss: 0.2835 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8776 - student_loss: 0.2937 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8760 - student_loss: 0.2853 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8779 - student_loss: 0.2809 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8826 - student_loss: 0.2783 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8805 - student_loss: 0.2773 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8869 - student_loss: 0.2740 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8760 - student_loss: 0.2801 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8805 - student_loss: 0.2748 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8847 - student_loss: 0.2718 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8828 - student_loss: 0.2650 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8821 - student_loss: 0.2709 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8864 - student_loss: 0.2611 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8900 - student_loss: 0.2570 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8874 - student_loss: 0.2651 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8897 - student_loss: 0.2604 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8926 - student_loss: 0.2552 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8935 - student_loss: 0.2487 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8942 - student_loss: 0.2516 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8964 - student_loss: 0.2529 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8940 - student_loss: 0.2470 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8876 - student_loss: 0.2559 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8969 - student_loss: 0.2452 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.8921 - student_loss: 0.2487 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8895 - student_loss: 0.2479 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8959 - student_loss: 0.2484 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9009 - student_loss: 0.2350 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8947 - student_loss: 0.2457 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9000 - student_loss: 0.2305 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8952 - student_loss: 0.2427 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8976 - student_loss: 0.2453 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 2s 11ms/step - binary_accuracy: 0.9004 - student_loss: 0.2350 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8985 - student_loss: 0.2350 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.8921 - student_loss: 0.2431 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9033 - student_loss: 0.2310 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9014 - student_loss: 0.2360 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.8981 - student_loss: 0.2412 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9052 - student_loss: 0.2216 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9009 - student_loss: 0.2388 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9045 - student_loss: 0.2337 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9033 - student_loss: 0.2250 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9042 - student_loss: 0.2294 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9045 - student_loss: 0.2159 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9092 - student_loss: 0.2127 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9085 - student_loss: 0.2210 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9038 - student_loss: 0.2304 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9071 - student_loss: 0.2227 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9109 - student_loss: 0.2179 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9125 - student_loss: 0.2163 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9040 - student_loss: 0.2258 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9061 - student_loss: 0.2162 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9125 - student_loss: 0.2082 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9123 - student_loss: 0.2143 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9114 - student_loss: 0.2112 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9085 - student_loss: 0.2192 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9087 - student_loss: 0.2207 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9014 - student_loss: 0.2194 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9130 - student_loss: 0.2134 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9118 - student_loss: 0.2101 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9118 - student_loss: 0.2155 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9130 - student_loss: 0.2045 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9114 - student_loss: 0.2220 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9118 - student_loss: 0.2152 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9085 - student_loss: 0.2143 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9106 - student_loss: 0.2115 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9147 - student_loss: 0.2074 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9161 - student_loss: 0.2018 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9123 - student_loss: 0.2044 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9180 - student_loss: 0.2079 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 2s 12ms/step - binary_accuracy: 0.9097 - student_loss: 0.2154 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9123 - student_loss: 0.2059 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9202 - student_loss: 0.2017 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9102 - student_loss: 0.2064 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9071 - student_loss: 0.2128 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 12ms/step - binary_accuracy: 0.9140 - student_loss: 0.2011 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9121 - student_loss: 0.2074 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 13ms/step - binary_accuracy: 0.9159 - student_loss: 0.2048 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 2s 11ms/step - binary_accuracy: 0.9173 - student_loss: 0.2020 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.8069 - student_loss: 0.3821\n",
      "[[572  61]\n",
      " [102 109]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "0.8068720102310181\n",
      "student_specificity\n",
      "0.9036334913112164\n",
      "student_sensitivity\n",
      "0.5165876777251185\n",
      "student_precision\n",
      "0.6411764705882353\n",
      "student_recall\n",
      "0.5165876777251185\n",
      "student_frr\n",
      "0.4834123222748815\n",
      "student_far\n",
      "0.09636650868878358\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_7.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "headed-mission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adequate-broadway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmpryvh4u__.h5\n",
      "Saved student model to: /tmp/tmpfj6gwk46.h5\n",
      "Size of gzipped Teacher model: 61145.00 bytes\n",
      "Size of gzipped Student model: 17062.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
