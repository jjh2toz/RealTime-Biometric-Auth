{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excessive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inner-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "attempted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "competitive-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 4\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "velvet-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 4, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.27506014989460326),\n",
    "        layers.LSTM(39),\n",
    "        layers.Dense(11, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 2, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.LSTM(20),\n",
    "        layers.Dense(5, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "renewable-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 480, 4)            28        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 160, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 160, 4)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 39)                6864      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 11)                440       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 7,344\n",
      "Trainable params: 7,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.5697 - binary_accuracy: 0.7490\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.5620 - binary_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.5565 - binary_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.5626 - binary_accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.5473 - binary_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.5225 - binary_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.4682 - binary_accuracy: 0.7631\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.4242 - binary_accuracy: 0.7916\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.4241 - binary_accuracy: 0.7940\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.3735 - binary_accuracy: 0.8339\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.3253 - binary_accuracy: 0.8565\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.2883 - binary_accuracy: 0.8769\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.2759 - binary_accuracy: 0.8802\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.2617 - binary_accuracy: 0.8881\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.2619 - binary_accuracy: 0.8850\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.2556 - binary_accuracy: 0.8933\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 10s 46ms/step - loss: 0.2597 - binary_accuracy: 0.8912\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 10s 46ms/step - loss: 0.2533 - binary_accuracy: 0.8945\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.2488 - binary_accuracy: 0.8952\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.2478 - binary_accuracy: 0.8893\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.2415 - binary_accuracy: 0.8931\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 11s 54ms/step - loss: 0.2361 - binary_accuracy: 0.8978\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 0.2364 - binary_accuracy: 0.9009\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 12s 56ms/step - loss: 0.2292 - binary_accuracy: 0.9040\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.2212 - binary_accuracy: 0.9059\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 11s 52ms/step - loss: 0.2207 - binary_accuracy: 0.9078\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 11s 50ms/step - loss: 0.2130 - binary_accuracy: 0.9130\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.2179 - binary_accuracy: 0.9095\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 11s 52ms/step - loss: 0.2172 - binary_accuracy: 0.9080\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 11s 53ms/step - loss: 0.2022 - binary_accuracy: 0.9144\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 11s 52ms/step - loss: 0.2020 - binary_accuracy: 0.9147\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 11s 52ms/step - loss: 0.2042 - binary_accuracy: 0.9161\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.1914 - binary_accuracy: 0.9194\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.1926 - binary_accuracy: 0.9183\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.1934 - binary_accuracy: 0.9178\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 11s 52ms/step - loss: 0.1943 - binary_accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 11s 52ms/step - loss: 0.1870 - binary_accuracy: 0.9232\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.1823 - binary_accuracy: 0.9270\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 11s 50ms/step - loss: 0.1776 - binary_accuracy: 0.9294\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 11s 51ms/step - loss: 0.1875 - binary_accuracy: 0.9211\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 11s 50ms/step - loss: 0.1807 - binary_accuracy: 0.9254\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1713 - binary_accuracy: 0.9306\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1757 - binary_accuracy: 0.9304\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1758 - binary_accuracy: 0.9254\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1749 - binary_accuracy: 0.9273\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1692 - binary_accuracy: 0.9297\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1662 - binary_accuracy: 0.9313\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1692 - binary_accuracy: 0.9327\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1733 - binary_accuracy: 0.9297\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1794 - binary_accuracy: 0.9263\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 11s 50ms/step - loss: 0.1610 - binary_accuracy: 0.9349\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1578 - binary_accuracy: 0.9316\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1642 - binary_accuracy: 0.9344\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1612 - binary_accuracy: 0.9361\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1669 - binary_accuracy: 0.9320\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1674 - binary_accuracy: 0.9275\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1612 - binary_accuracy: 0.9356\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1551 - binary_accuracy: 0.9370\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1563 - binary_accuracy: 0.9361\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 10s 49ms/step - loss: 0.1580 - binary_accuracy: 0.9365\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 10s 47ms/step - loss: 0.1597 - binary_accuracy: 0.9304\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 10s 47ms/step - loss: 0.1535 - binary_accuracy: 0.9346\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.1570 - binary_accuracy: 0.9368\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1448 - binary_accuracy: 0.9399\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 10s 46ms/step - loss: 0.1545 - binary_accuracy: 0.9377\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 10s 47ms/step - loss: 0.1479 - binary_accuracy: 0.9392\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 10s 46ms/step - loss: 0.1500 - binary_accuracy: 0.9396\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 10s 47ms/step - loss: 0.1447 - binary_accuracy: 0.9420\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 10s 46ms/step - loss: 0.1383 - binary_accuracy: 0.9432\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 10s 46ms/step - loss: 0.1427 - binary_accuracy: 0.9415\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.1500 - binary_accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.1349 - binary_accuracy: 0.9461\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.1552 - binary_accuracy: 0.9363\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.1468 - binary_accuracy: 0.9413\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.1478 - binary_accuracy: 0.9399\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.1455 - binary_accuracy: 0.9430\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1361 - binary_accuracy: 0.9430\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1452 - binary_accuracy: 0.9399\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1446 - binary_accuracy: 0.9399\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.1401 - binary_accuracy: 0.9415\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1352 - binary_accuracy: 0.9399\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.1375 - binary_accuracy: 0.9437\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1351 - binary_accuracy: 0.9451\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1400 - binary_accuracy: 0.9446\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1411 - binary_accuracy: 0.9425\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1326 - binary_accuracy: 0.9449\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1291 - binary_accuracy: 0.9449\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.1383 - binary_accuracy: 0.9468\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1329 - binary_accuracy: 0.9484\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1369 - binary_accuracy: 0.9463\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.1385 - binary_accuracy: 0.9430\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1434 - binary_accuracy: 0.9420\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1269 - binary_accuracy: 0.9475\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1271 - binary_accuracy: 0.9463\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1302 - binary_accuracy: 0.9477\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1237 - binary_accuracy: 0.9477\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1327 - binary_accuracy: 0.9415\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1335 - binary_accuracy: 0.9465\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1207 - binary_accuracy: 0.9544\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1265 - binary_accuracy: 0.9484\n",
      "27/27 - 0s - loss: 0.3303 - binary_accuracy: 0.8945\n",
      "[[607  26]\n",
      " [ 63 148]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.8945497870445251\n",
      "teacher_specificity\n",
      "0.9589257503949447\n",
      "teacher_sensitivity\n",
      "0.7014218009478673\n",
      "teacher_precision\n",
      "0.8505747126436781\n",
      "teacher_recall\n",
      "0.7014218009478673\n",
      "teacher_frr\n",
      "0.2985781990521327\n",
      "teacher_far\n",
      "0.04107424960505529\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.00287010197769885),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_5.h5')\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accurate-badge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.7500 - student_loss: 0.5679 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.7500 - student_loss: 0.5461 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.7500 - student_loss: 0.5265 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.7500 - student_loss: 0.5259 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.7500 - student_loss: 0.5073 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.7500 - student_loss: 0.4748 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.7837 - student_loss: 0.4545 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 7s 34ms/step - binary_accuracy: 0.7507 - student_loss: 0.4683 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.7821 - student_loss: 0.4522 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8165 - student_loss: 0.4338 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8096 - student_loss: 0.4310 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8054 - student_loss: 0.4281 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 7s 34ms/step - binary_accuracy: 0.8230 - student_loss: 0.4112 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8139 - student_loss: 0.4190 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8239 - student_loss: 0.3961 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.8306 - student_loss: 0.3825 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8593 - student_loss: 0.3462 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8693 - student_loss: 0.3188 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8814 - student_loss: 0.3048 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8793 - student_loss: 0.3099 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8826 - student_loss: 0.2912 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 7s 34ms/step - binary_accuracy: 0.8852 - student_loss: 0.2893 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 7s 34ms/step - binary_accuracy: 0.8912 - student_loss: 0.2747 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 7s 35ms/step - binary_accuracy: 0.8857 - student_loss: 0.2878 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.8933 - student_loss: 0.2676 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8957 - student_loss: 0.2654 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8966 - student_loss: 0.2696 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.8895 - student_loss: 0.2665 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8904 - student_loss: 0.2728 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8902 - student_loss: 0.2726 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8928 - student_loss: 0.2610 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8940 - student_loss: 0.2729 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.8959 - student_loss: 0.2593 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.8935 - student_loss: 0.2666 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.8881 - student_loss: 0.2658 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8978 - student_loss: 0.2479 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.9000 - student_loss: 0.2576 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.9014 - student_loss: 0.2491 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.8995 - student_loss: 0.2608 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.9019 - student_loss: 0.2551 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8995 - student_loss: 0.2464 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9054 - student_loss: 0.2499 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.8997 - student_loss: 0.2557 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8926 - student_loss: 0.2592 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.8845 - student_loss: 0.2652 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.8973 - student_loss: 0.2565 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8992 - student_loss: 0.2583 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.9014 - student_loss: 0.2458 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.9057 - student_loss: 0.2377 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.8966 - student_loss: 0.2416 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.9045 - student_loss: 0.2387 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.9035 - student_loss: 0.2356 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.9021 - student_loss: 0.2461 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.9076 - student_loss: 0.2397 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 8s 36ms/step - binary_accuracy: 0.9047 - student_loss: 0.2438 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 8s 37ms/step - binary_accuracy: 0.9038 - student_loss: 0.2393 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.9076 - student_loss: 0.2258 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.8997 - student_loss: 0.2442 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9054 - student_loss: 0.2305 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.9068 - student_loss: 0.2366 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.9047 - student_loss: 0.2330 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9019 - student_loss: 0.2427 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9009 - student_loss: 0.2505 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.8957 - student_loss: 0.2568 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9118 - student_loss: 0.2307 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9078 - student_loss: 0.2232 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9099 - student_loss: 0.2231 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9054 - student_loss: 0.2318 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9097 - student_loss: 0.2282 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.9116 - student_loss: 0.2235 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9061 - student_loss: 0.2449 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9106 - student_loss: 0.2245 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9087 - student_loss: 0.2246 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9092 - student_loss: 0.2282 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9071 - student_loss: 0.2321 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9111 - student_loss: 0.2244 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9123 - student_loss: 0.2216 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9106 - student_loss: 0.2204 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9128 - student_loss: 0.2248 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.9085 - student_loss: 0.2266 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9109 - student_loss: 0.2251 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9057 - student_loss: 0.2268 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9092 - student_loss: 0.2261 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 8s 38ms/step - binary_accuracy: 0.9133 - student_loss: 0.2178 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9137 - student_loss: 0.2245 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9078 - student_loss: 0.2238 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9087 - student_loss: 0.2269 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9187 - student_loss: 0.2055 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9099 - student_loss: 0.2273 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9125 - student_loss: 0.2233 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9068 - student_loss: 0.2280 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9109 - student_loss: 0.2246 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 9s 40ms/step - binary_accuracy: 0.9095 - student_loss: 0.2290 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9078 - student_loss: 0.2198 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9116 - student_loss: 0.2180 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9116 - student_loss: 0.2223 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9125 - student_loss: 0.2122 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9118 - student_loss: 0.2163 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 8s 40ms/step - binary_accuracy: 0.9142 - student_loss: 0.2163 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 8s 39ms/step - binary_accuracy: 0.9123 - student_loss: 0.2165 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.8578 - student_loss: 0.4247\n",
      "[[630   3]\n",
      " [117  94]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "0.8578199148178101\n",
      "student_specificity\n",
      "0.995260663507109\n",
      "student_sensitivity\n",
      "0.44549763033175355\n",
      "student_precision\n",
      "0.9690721649484536\n",
      "student_recall\n",
      "0.44549763033175355\n",
      "student_frr\n",
      "0.5545023696682464\n",
      "student_far\n",
      "0.004739336492890996\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_5.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "headed-mission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "practical-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmprt1l1jdt.h5\n",
      "Saved student model to: /tmp/tmpx0s_3um9.h5\n",
      "Size of gzipped Teacher model: 29997.00 bytes\n",
      "Size of gzipped Student model: 9862.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
