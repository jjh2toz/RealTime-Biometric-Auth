{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 0\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 59, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 43, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.4259138385905129),\n",
    "        layers.LSTM(64),\n",
    "        layers.Dense(36, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 16, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 8, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.LSTM(20),\n",
    "        layers.Dense(5, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 480, 59)           413       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 160, 59)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 160, 43)           7654      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 53, 43)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 53, 43)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                27648     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 36)                2340      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 37        \n",
      "=================================================================\n",
      "Total params: 38,092\n",
      "Trainable params: 38,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 6s 20ms/step - loss: 0.5522 - binary_accuracy: 0.7469\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.3994 - binary_accuracy: 0.7973\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.3754 - binary_accuracy: 0.8286\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.3462 - binary_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.3475 - binary_accuracy: 0.8508\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.3133 - binary_accuracy: 0.8812\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2996 - binary_accuracy: 0.8856\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2840 - binary_accuracy: 0.8897\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2427 - binary_accuracy: 0.9122\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2588 - binary_accuracy: 0.9023\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2559 - binary_accuracy: 0.8974\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1983 - binary_accuracy: 0.9264\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2272 - binary_accuracy: 0.9173\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2195 - binary_accuracy: 0.9187\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2095 - binary_accuracy: 0.9235\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2234 - binary_accuracy: 0.9168\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1830 - binary_accuracy: 0.9342\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1966 - binary_accuracy: 0.9265\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1916 - binary_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1899 - binary_accuracy: 0.9286\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1659 - binary_accuracy: 0.9344\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1768 - binary_accuracy: 0.9309\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.2006 - binary_accuracy: 0.9197\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1650 - binary_accuracy: 0.9381\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1651 - binary_accuracy: 0.9369\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1794 - binary_accuracy: 0.9336\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1662 - binary_accuracy: 0.9392\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.1680 - binary_accuracy: 0.9339\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1397 - binary_accuracy: 0.9497\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1442 - binary_accuracy: 0.9443\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1492 - binary_accuracy: 0.9439\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1492 - binary_accuracy: 0.9411\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1486 - binary_accuracy: 0.9495\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1381 - binary_accuracy: 0.9517\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1462 - binary_accuracy: 0.9448\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1578 - binary_accuracy: 0.9394\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1462 - binary_accuracy: 0.9437\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1406 - binary_accuracy: 0.9511\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1350 - binary_accuracy: 0.9515\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1249 - binary_accuracy: 0.9519\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1146 - binary_accuracy: 0.9533\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1373 - binary_accuracy: 0.9491\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1312 - binary_accuracy: 0.9536\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1238 - binary_accuracy: 0.9552\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1237 - binary_accuracy: 0.9538\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1179 - binary_accuracy: 0.9540\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1198 - binary_accuracy: 0.9499\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1318 - binary_accuracy: 0.9446\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1099 - binary_accuracy: 0.9661\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1426 - binary_accuracy: 0.9517\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1066 - binary_accuracy: 0.9627\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1416 - binary_accuracy: 0.9466\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1256 - binary_accuracy: 0.9494\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0935 - binary_accuracy: 0.9668\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0954 - binary_accuracy: 0.9671\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0993 - binary_accuracy: 0.9657\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1139 - binary_accuracy: 0.9549\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0909 - binary_accuracy: 0.9690\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0979 - binary_accuracy: 0.9670\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1043 - binary_accuracy: 0.9623\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0979 - binary_accuracy: 0.9595\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1053 - binary_accuracy: 0.9563\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0893 - binary_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0837 - binary_accuracy: 0.9684\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0917 - binary_accuracy: 0.9642\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1121 - binary_accuracy: 0.9594\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0930 - binary_accuracy: 0.9654\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0765 - binary_accuracy: 0.9729\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0914 - binary_accuracy: 0.9669\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.1010 - binary_accuracy: 0.9628\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1046 - binary_accuracy: 0.9595\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0804 - binary_accuracy: 0.9681\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0851 - binary_accuracy: 0.9650\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0876 - binary_accuracy: 0.9682\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0795 - binary_accuracy: 0.9668\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0763 - binary_accuracy: 0.9710\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.1010 - binary_accuracy: 0.9640\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0722 - binary_accuracy: 0.9731\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0707 - binary_accuracy: 0.9717\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0898 - binary_accuracy: 0.9657\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0679 - binary_accuracy: 0.9750\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0856 - binary_accuracy: 0.9660\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0563 - binary_accuracy: 0.9793\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0576 - binary_accuracy: 0.9782\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0559 - binary_accuracy: 0.9790\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0563 - binary_accuracy: 0.9789\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0666 - binary_accuracy: 0.9766\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0810 - binary_accuracy: 0.9668\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0666 - binary_accuracy: 0.9755\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0661 - binary_accuracy: 0.9772\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0612 - binary_accuracy: 0.9818\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0585 - binary_accuracy: 0.9747\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0626 - binary_accuracy: 0.9790\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0873 - binary_accuracy: 0.9686\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0598 - binary_accuracy: 0.9764\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0421 - binary_accuracy: 0.9846\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0599 - binary_accuracy: 0.9813\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0489 - binary_accuracy: 0.9810\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0447 - binary_accuracy: 0.9847\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0704 - binary_accuracy: 0.9713\n",
      "27/27 - 1s - loss: 0.1417 - binary_accuracy: 0.9526\n",
      "[[611  22]\n",
      " [ 18 193]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.9526066184043884\n",
      "teacher_specificity\n",
      "0.9652448657187994\n",
      "teacher_sensitivity\n",
      "0.9146919431279621\n",
      "teacher_precision\n",
      "0.8976744186046511\n",
      "teacher_recall\n",
      "0.9146919431279621\n",
      "teacher_frr\n",
      "0.08530805687203792\n",
      "teacher_far\n",
      "0.03475513428120063\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0005962163993143515),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_1.h5')\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 6s 18ms/step - binary_accuracy: 0.7486 - student_loss: 0.5188 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.7811 - student_loss: 0.4088 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8176 - student_loss: 0.3879 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.7964 - student_loss: 0.4231 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8205 - student_loss: 0.3901 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8170 - student_loss: 0.3849 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8248 - student_loss: 0.3793 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8299 - student_loss: 0.3711 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8171 - student_loss: 0.3688 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8363 - student_loss: 0.3602 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8272 - student_loss: 0.3605 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8448 - student_loss: 0.3471 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8558 - student_loss: 0.3397 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8616 - student_loss: 0.3317 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8485 - student_loss: 0.3329 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8485 - student_loss: 0.3312 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8601 - student_loss: 0.3335 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8630 - student_loss: 0.3102 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8788 - student_loss: 0.3071 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8751 - student_loss: 0.2955 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8922 - student_loss: 0.2904 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8825 - student_loss: 0.2816 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8765 - student_loss: 0.2902 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8941 - student_loss: 0.2681 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8902 - student_loss: 0.2780 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8895 - student_loss: 0.2744 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8848 - student_loss: 0.2683 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8989 - student_loss: 0.2621 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9045 - student_loss: 0.2581 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9027 - student_loss: 0.2516 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9016 - student_loss: 0.2476 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9028 - student_loss: 0.2503 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9011 - student_loss: 0.2378 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9066 - student_loss: 0.2390 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8973 - student_loss: 0.2359 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9091 - student_loss: 0.2348 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.8999 - student_loss: 0.2374 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9053 - student_loss: 0.2334 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9208 - student_loss: 0.2283 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9164 - student_loss: 0.2222 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9167 - student_loss: 0.2248 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9136 - student_loss: 0.2252 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9194 - student_loss: 0.2140 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9239 - student_loss: 0.2136 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9157 - student_loss: 0.2168 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9258 - student_loss: 0.2157 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9279 - student_loss: 0.2097 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9207 - student_loss: 0.2130 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9217 - student_loss: 0.2252 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9236 - student_loss: 0.2134 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9120 - student_loss: 0.2150 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9206 - student_loss: 0.2147 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9184 - student_loss: 0.2075 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9199 - student_loss: 0.2075 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9170 - student_loss: 0.2057 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9253 - student_loss: 0.2021 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9159 - student_loss: 0.2073 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9193 - student_loss: 0.2037 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9186 - student_loss: 0.1992 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9253 - student_loss: 0.2009 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9169 - student_loss: 0.1987 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9315 - student_loss: 0.1936 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9307 - student_loss: 0.1980 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9235 - student_loss: 0.1912 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9250 - student_loss: 0.1887 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9346 - student_loss: 0.1952 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9297 - student_loss: 0.1900 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9266 - student_loss: 0.1835 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9261 - student_loss: 0.1945 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9161 - student_loss: 0.1905 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9231 - student_loss: 0.1913 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9229 - student_loss: 0.1930 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9337 - student_loss: 0.1871 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9253 - student_loss: 0.1862 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9181 - student_loss: 0.1942 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9353 - student_loss: 0.1860 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9244 - student_loss: 0.1860 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9334 - student_loss: 0.1882 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9313 - student_loss: 0.1823 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9266 - student_loss: 0.1854 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9313 - student_loss: 0.1895 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9328 - student_loss: 0.1842 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9375 - student_loss: 0.1765 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9257 - student_loss: 0.1884 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9353 - student_loss: 0.1849 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 17ms/step - binary_accuracy: 0.9354 - student_loss: 0.1821 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9310 - student_loss: 0.1842 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9327 - student_loss: 0.1794 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9336 - student_loss: 0.1837 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9340 - student_loss: 0.1701 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9415 - student_loss: 0.1798 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9297 - student_loss: 0.1720 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9252 - student_loss: 0.1820 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9246 - student_loss: 0.1850 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9280 - student_loss: 0.1789 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9333 - student_loss: 0.1814 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9363 - student_loss: 0.1728 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9339 - student_loss: 0.1741 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9328 - student_loss: 0.1825 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 15ms/step - binary_accuracy: 0.9358 - student_loss: 0.1748 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.9408 - student_loss: 0.0011\n",
      "[[603  30]\n",
      " [ 20 191]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "[0.9407582879066467, 0.0010629970347508788]\n",
      "student_specificity\n",
      "0.95260663507109\n",
      "student_sensitivity\n",
      "0.9052132701421801\n",
      "student_precision\n",
      "0.8642533936651584\n",
      "student_recall\n",
      "0.9052132701421801\n",
      "student_frr\n",
      "0.0947867298578199\n",
      "student_far\n",
      "0.04739336492890995\n",
      "0.04739336492890995\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_1.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmpsa1ohh3q.h5\n",
      "Saved student model to: /tmp/tmpfh3f6p2h.h5\n",
      "Size of gzipped Teacher model: 144941.00 bytes\n",
      "Size of gzipped Student model: 13764.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
