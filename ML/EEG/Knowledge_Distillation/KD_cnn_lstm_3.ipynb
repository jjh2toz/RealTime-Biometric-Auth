{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "excessive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "inner-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "attempted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "competitive-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 2\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "velvet-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 18, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 58, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5201428691759254),\n",
    "        layers.LSTM(17),\n",
    "        layers.Dense(85, activation = 'relu'),\n",
    "        layers.Dense(19, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 9, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 29, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.LSTM(8),\n",
    "        layers.Dense(40, activation = 'relu'),\n",
    "        layers.Dense(9, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "renewable-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 480, 18)           126       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 160, 18)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 160, 58)           3190      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 53, 58)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 53, 58)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 17)                5168      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 85)                1530      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 19)                1634      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 20        \n",
      "=================================================================\n",
      "Total params: 11,668\n",
      "Trainable params: 11,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.5104 - binary_accuracy: 0.7460\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.3907 - binary_accuracy: 0.7909\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.3615 - binary_accuracy: 0.8227\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.3040 - binary_accuracy: 0.8586\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.2833 - binary_accuracy: 0.8762\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.2572 - binary_accuracy: 0.8933\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.2318 - binary_accuracy: 0.9047\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.2161 - binary_accuracy: 0.9111\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1944 - binary_accuracy: 0.9194\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1853 - binary_accuracy: 0.9270\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1761 - binary_accuracy: 0.9256\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1706 - binary_accuracy: 0.9301\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1613 - binary_accuracy: 0.9327\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1499 - binary_accuracy: 0.9399\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1548 - binary_accuracy: 0.9387\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1558 - binary_accuracy: 0.9370\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1391 - binary_accuracy: 0.9439\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1367 - binary_accuracy: 0.9413\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 0.1406 - binary_accuracy: 0.9451\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1503 - binary_accuracy: 0.9387\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1384 - binary_accuracy: 0.9420\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1337 - binary_accuracy: 0.9475\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1379 - binary_accuracy: 0.9423\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1221 - binary_accuracy: 0.9501\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1302 - binary_accuracy: 0.9494\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1280 - binary_accuracy: 0.9446\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1294 - binary_accuracy: 0.9470\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1159 - binary_accuracy: 0.9510\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1155 - binary_accuracy: 0.9563\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1180 - binary_accuracy: 0.9525\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1118 - binary_accuracy: 0.9506\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1019 - binary_accuracy: 0.9598\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1031 - binary_accuracy: 0.9570\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0954 - binary_accuracy: 0.9596\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1126 - binary_accuracy: 0.9520\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1069 - binary_accuracy: 0.9567\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1033 - binary_accuracy: 0.9587\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.1031 - binary_accuracy: 0.9596\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0929 - binary_accuracy: 0.9651\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0936 - binary_accuracy: 0.9627\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0943 - binary_accuracy: 0.9587\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0887 - binary_accuracy: 0.9639\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0909 - binary_accuracy: 0.9639\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0986 - binary_accuracy: 0.9632\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0843 - binary_accuracy: 0.9648\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0841 - binary_accuracy: 0.9679\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0873 - binary_accuracy: 0.9629\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0934 - binary_accuracy: 0.9641\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0841 - binary_accuracy: 0.9665\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0868 - binary_accuracy: 0.9651\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0805 - binary_accuracy: 0.9710\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0877 - binary_accuracy: 0.9639\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0801 - binary_accuracy: 0.9677\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0813 - binary_accuracy: 0.9701\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0739 - binary_accuracy: 0.9708\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0758 - binary_accuracy: 0.9691\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0771 - binary_accuracy: 0.9660\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0853 - binary_accuracy: 0.9684\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0752 - binary_accuracy: 0.9701\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0758 - binary_accuracy: 0.9696\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0676 - binary_accuracy: 0.9743\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0751 - binary_accuracy: 0.9684\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0716 - binary_accuracy: 0.9710\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0751 - binary_accuracy: 0.9701\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0617 - binary_accuracy: 0.9758\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0688 - binary_accuracy: 0.9746\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0714 - binary_accuracy: 0.9717\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0630 - binary_accuracy: 0.9755\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0694 - binary_accuracy: 0.9724\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0829 - binary_accuracy: 0.9658\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0707 - binary_accuracy: 0.9741\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0552 - binary_accuracy: 0.9779\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0681 - binary_accuracy: 0.9715\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0679 - binary_accuracy: 0.9710\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0671 - binary_accuracy: 0.9755\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0618 - binary_accuracy: 0.9750\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0599 - binary_accuracy: 0.9767\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0578 - binary_accuracy: 0.9788\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0583 - binary_accuracy: 0.9774\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0560 - binary_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.0641 - binary_accuracy: 0.9753\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0585 - binary_accuracy: 0.9760\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0575 - binary_accuracy: 0.9777\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0598 - binary_accuracy: 0.9793\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0656 - binary_accuracy: 0.9731\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0585 - binary_accuracy: 0.9791\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0566 - binary_accuracy: 0.9788\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0610 - binary_accuracy: 0.9760\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0525 - binary_accuracy: 0.9796\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0539 - binary_accuracy: 0.9791\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0536 - binary_accuracy: 0.9810\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0549 - binary_accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0519 - binary_accuracy: 0.9805\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0531 - binary_accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0518 - binary_accuracy: 0.9793\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0575 - binary_accuracy: 0.9765\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0523 - binary_accuracy: 0.9788\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0603 - binary_accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0541 - binary_accuracy: 0.9788\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0552 - binary_accuracy: 0.9810\n",
      "27/27 - 0s - loss: 0.2211 - binary_accuracy: 0.9336\n",
      "[[624   9]\n",
      " [ 47 164]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.9336493015289307\n",
      "teacher_specificity\n",
      "0.985781990521327\n",
      "teacher_sensitivity\n",
      "0.7772511848341233\n",
      "teacher_precision\n",
      "0.9479768786127167\n",
      "teacher_recall\n",
      "0.7772511848341233\n",
      "teacher_frr\n",
      "0.22274881516587677\n",
      "teacher_far\n",
      "0.014218009478672985\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0018805757938221066),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_3.h5')\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "accurate-badge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.7483 - student_loss: 0.5492 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.7669 - student_loss: 0.4338 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.7956 - student_loss: 0.4010 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8035 - student_loss: 0.3815 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8398 - student_loss: 0.3416 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.8484 - student_loss: 0.3236 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.8626 - student_loss: 0.3067 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8752 - student_loss: 0.2828 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8923 - student_loss: 0.2551 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.8969 - student_loss: 0.2424 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9019 - student_loss: 0.2377 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9085 - student_loss: 0.2172 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9085 - student_loss: 0.2135 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9097 - student_loss: 0.2118 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9083 - student_loss: 0.2207 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9133 - student_loss: 0.2048 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9190 - student_loss: 0.1962 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9251 - student_loss: 0.1835 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9282 - student_loss: 0.1795 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.9285 - student_loss: 0.1864 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9223 - student_loss: 0.1848 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9320 - student_loss: 0.1733 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9285 - student_loss: 0.1736 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9287 - student_loss: 0.1709 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9318 - student_loss: 0.1626 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9354 - student_loss: 0.1570 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9346 - student_loss: 0.1589 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9413 - student_loss: 0.1494 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9363 - student_loss: 0.1535 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9401 - student_loss: 0.1532 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9373 - student_loss: 0.1509 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9423 - student_loss: 0.1461 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9418 - student_loss: 0.1488 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9442 - student_loss: 0.1409 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9406 - student_loss: 0.1452 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9456 - student_loss: 0.1372 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9437 - student_loss: 0.1417 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9461 - student_loss: 0.1409 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9461 - student_loss: 0.1368 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9456 - student_loss: 0.1392 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9501 - student_loss: 0.1251 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9515 - student_loss: 0.1322 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9461 - student_loss: 0.1288 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9496 - student_loss: 0.1266 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9548 - student_loss: 0.1188 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9480 - student_loss: 0.1330 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9520 - student_loss: 0.1203 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9534 - student_loss: 0.1163 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9551 - student_loss: 0.1181 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9491 - student_loss: 0.1230 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9548 - student_loss: 0.1116 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9489 - student_loss: 0.1265 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9537 - student_loss: 0.1180 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9551 - student_loss: 0.1162 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9587 - student_loss: 0.1092 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9546 - student_loss: 0.1125 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9556 - student_loss: 0.1125 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9563 - student_loss: 0.1084 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9591 - student_loss: 0.1033 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9527 - student_loss: 0.1099 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9584 - student_loss: 0.1074 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9556 - student_loss: 0.1129 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9589 - student_loss: 0.1021 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9596 - student_loss: 0.1030 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9617 - student_loss: 0.1009 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9594 - student_loss: 0.1029 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9520 - student_loss: 0.1169 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9582 - student_loss: 0.1007 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9522 - student_loss: 0.1084 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9608 - student_loss: 0.1055 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9610 - student_loss: 0.0939 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9603 - student_loss: 0.1036 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9644 - student_loss: 0.0908 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9570 - student_loss: 0.1070 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9627 - student_loss: 0.0938 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9589 - student_loss: 0.1021 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9596 - student_loss: 0.0982 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9601 - student_loss: 0.1003 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9625 - student_loss: 0.0949 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9615 - student_loss: 0.1000 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9627 - student_loss: 0.0854 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9589 - student_loss: 0.0975 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9587 - student_loss: 0.1002 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9622 - student_loss: 0.0916 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9641 - student_loss: 0.0952 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9641 - student_loss: 0.0946 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9577 - student_loss: 0.1005 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9629 - student_loss: 0.0930 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9620 - student_loss: 0.0895 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9653 - student_loss: 0.0853 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9577 - student_loss: 0.0914 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9610 - student_loss: 0.0895 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9641 - student_loss: 0.0908 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9653 - student_loss: 0.0820 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9601 - student_loss: 0.0978 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9651 - student_loss: 0.0851 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9672 - student_loss: 0.0859 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9601 - student_loss: 0.0894 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9665 - student_loss: 0.0842 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9629 - student_loss: 0.0889 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.9289 - student_loss: 0.1669\n",
      "[[621  12]\n",
      " [ 48 163]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "0.928909957408905\n",
      "student_specificity\n",
      "0.981042654028436\n",
      "student_sensitivity\n",
      "0.7725118483412322\n",
      "student_precision\n",
      "0.9314285714285714\n",
      "student_recall\n",
      "0.7725118483412322\n",
      "student_frr\n",
      "0.22748815165876776\n",
      "student_far\n",
      "0.018957345971563982\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_3.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "headed-mission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "introductory-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmps9rvhsvw.h5\n",
      "Saved student model to: /tmp/tmp459jzvml.h5\n",
      "Size of gzipped Teacher model: 46721.00 bytes\n",
      "Size of gzipped Student model: 13567.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
