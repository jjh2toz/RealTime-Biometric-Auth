{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "excessive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "inner-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "attempted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "competitive-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 5\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "velvet-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 31, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 41, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 27, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5876665731188462),\n",
    "        layers.LSTM(139),\n",
    "        layers.Dense(80, activation = 'relu'),\n",
    "        layers.Dense(31, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 16, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 8, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.LSTM(20),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(5, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "renewable-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 480, 31)           217       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 160, 31)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 160, 41)           3854      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 53, 41)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 53, 27)            3348      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 17, 27)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 17, 27)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 139)               92852     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 80)                11200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 31)                2511      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 114,014\n",
      "Trainable params: 114,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.3565 - binary_accuracy: 0.8386\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.2120 - binary_accuracy: 0.9066\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1956 - binary_accuracy: 0.9123\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1786 - binary_accuracy: 0.9211\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1670 - binary_accuracy: 0.9221\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1737 - binary_accuracy: 0.9216\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1664 - binary_accuracy: 0.9259\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1557 - binary_accuracy: 0.9308\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1493 - binary_accuracy: 0.9311\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1502 - binary_accuracy: 0.9337\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 0.1428 - binary_accuracy: 0.9354\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1452 - binary_accuracy: 0.9349\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1446 - binary_accuracy: 0.9361\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1427 - binary_accuracy: 0.9342\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1357 - binary_accuracy: 0.9406\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1348 - binary_accuracy: 0.9418\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1323 - binary_accuracy: 0.9430\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1237 - binary_accuracy: 0.9449\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 0.1162 - binary_accuracy: 0.9482\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1143 - binary_accuracy: 0.9482\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1108 - binary_accuracy: 0.9529\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1166 - binary_accuracy: 0.9501\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1140 - binary_accuracy: 0.9525\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1003 - binary_accuracy: 0.9537\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1055 - binary_accuracy: 0.9572\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0960 - binary_accuracy: 0.9587\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0990 - binary_accuracy: 0.9610\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0906 - binary_accuracy: 0.9606\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0901 - binary_accuracy: 0.9636\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0899 - binary_accuracy: 0.9636\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0874 - binary_accuracy: 0.9655\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0802 - binary_accuracy: 0.9660\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0914 - binary_accuracy: 0.9636\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0788 - binary_accuracy: 0.9698\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0775 - binary_accuracy: 0.9674\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0693 - binary_accuracy: 0.9715\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0623 - binary_accuracy: 0.9753\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0672 - binary_accuracy: 0.9734\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0605 - binary_accuracy: 0.9743\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0583 - binary_accuracy: 0.9779\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 0.0657 - binary_accuracy: 0.9746\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0549 - binary_accuracy: 0.9786\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0524 - binary_accuracy: 0.9796\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0574 - binary_accuracy: 0.9772\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0563 - binary_accuracy: 0.9772\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0505 - binary_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0478 - binary_accuracy: 0.9817\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0498 - binary_accuracy: 0.9803\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0428 - binary_accuracy: 0.9831\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0462 - binary_accuracy: 0.9812\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0453 - binary_accuracy: 0.9831\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0391 - binary_accuracy: 0.9843\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0455 - binary_accuracy: 0.9843\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0428 - binary_accuracy: 0.9836\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0404 - binary_accuracy: 0.9836\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0420 - binary_accuracy: 0.9838\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0360 - binary_accuracy: 0.9860\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0440 - binary_accuracy: 0.9829\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0333 - binary_accuracy: 0.9876\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0351 - binary_accuracy: 0.9848\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0415 - binary_accuracy: 0.9843\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0341 - binary_accuracy: 0.9874\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0348 - binary_accuracy: 0.9872\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0324 - binary_accuracy: 0.9876\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0369 - binary_accuracy: 0.9865\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0304 - binary_accuracy: 0.9876\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0303 - binary_accuracy: 0.9884\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0233 - binary_accuracy: 0.9922\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0330 - binary_accuracy: 0.9891\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0253 - binary_accuracy: 0.9905\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0339 - binary_accuracy: 0.9886\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0328 - binary_accuracy: 0.9888\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0276 - binary_accuracy: 0.9893\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0242 - binary_accuracy: 0.9907\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0328 - binary_accuracy: 0.9876\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0332 - binary_accuracy: 0.9865\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0268 - binary_accuracy: 0.9905\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0348 - binary_accuracy: 0.9876\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0196 - binary_accuracy: 0.9931\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0204 - binary_accuracy: 0.9926\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0322 - binary_accuracy: 0.9860\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0212 - binary_accuracy: 0.9922\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0312 - binary_accuracy: 0.9886\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0341 - binary_accuracy: 0.9869\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0265 - binary_accuracy: 0.9879\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0166 - binary_accuracy: 0.9950\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0176 - binary_accuracy: 0.9938\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0170 - binary_accuracy: 0.9941\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0198 - binary_accuracy: 0.9926\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0175 - binary_accuracy: 0.9941\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9867\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0242 - binary_accuracy: 0.9907\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0272 - binary_accuracy: 0.9895\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0220 - binary_accuracy: 0.9919\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0241 - binary_accuracy: 0.9903\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0166 - binary_accuracy: 0.9926\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0212 - binary_accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0208 - binary_accuracy: 0.9919\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0230 - binary_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 0.0179 - binary_accuracy: 0.9938\n",
      "27/27 - 0s - loss: 0.1207 - binary_accuracy: 0.9656\n",
      "[[612  21]\n",
      " [  8 203]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.9656398296356201\n",
      "teacher_specificity\n",
      "0.966824644549763\n",
      "teacher_sensitivity\n",
      "0.9620853080568721\n",
      "teacher_precision\n",
      "0.90625\n",
      "teacher_recall\n",
      "0.9620853080568721\n",
      "teacher_frr\n",
      "0.037914691943127965\n",
      "teacher_far\n",
      "0.03317535545023697\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0004822022064680656),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_6.h5')\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accurate-badge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.7678 - student_loss: 0.4653 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.8762 - student_loss: 0.2985 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8776 - student_loss: 0.2550 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.8942 - student_loss: 0.2370 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9028 - student_loss: 0.2141 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.9104 - student_loss: 0.2061 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9087 - student_loss: 0.2023 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9071 - student_loss: 0.1968 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9125 - student_loss: 0.1845 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9116 - student_loss: 0.1873 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9187 - student_loss: 0.1779 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9185 - student_loss: 0.1781 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9185 - student_loss: 0.1687 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9199 - student_loss: 0.1708 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9225 - student_loss: 0.1699 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9185 - student_loss: 0.1690 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9197 - student_loss: 0.1750 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9285 - student_loss: 0.1580 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9237 - student_loss: 0.1555 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9242 - student_loss: 0.1653 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9249 - student_loss: 0.1542 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9330 - student_loss: 0.1514 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9292 - student_loss: 0.1548 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9273 - student_loss: 0.1570 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9344 - student_loss: 0.1454 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 5s 21ms/step - binary_accuracy: 0.9339 - student_loss: 0.1445 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9342 - student_loss: 0.1414 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9327 - student_loss: 0.1505 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9332 - student_loss: 0.1437 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9385 - student_loss: 0.1453 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9413 - student_loss: 0.1309 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9456 - student_loss: 0.1335 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9408 - student_loss: 0.1343 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9408 - student_loss: 0.1313 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9425 - student_loss: 0.1304 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9434 - student_loss: 0.1323 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9458 - student_loss: 0.1254 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9475 - student_loss: 0.1247 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9475 - student_loss: 0.1210 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9489 - student_loss: 0.1182 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9461 - student_loss: 0.1194 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 5s 22ms/step - binary_accuracy: 0.9506 - student_loss: 0.1185 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9529 - student_loss: 0.1119 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9513 - student_loss: 0.1070 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9520 - student_loss: 0.1142 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9489 - student_loss: 0.1124 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9567 - student_loss: 0.1040 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9594 - student_loss: 0.1003 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9563 - student_loss: 0.1036 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9527 - student_loss: 0.1180 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9591 - student_loss: 0.1041 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9632 - student_loss: 0.0957 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 21ms/step - binary_accuracy: 0.9596 - student_loss: 0.0987 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9551 - student_loss: 0.1107 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9663 - student_loss: 0.0879 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9603 - student_loss: 0.0956 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9639 - student_loss: 0.0928 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9682 - student_loss: 0.0905 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9651 - student_loss: 0.0905 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9587 - student_loss: 0.0966 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9672 - student_loss: 0.0863 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9665 - student_loss: 0.0866 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9601 - student_loss: 0.0892 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9655 - student_loss: 0.0900 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9674 - student_loss: 0.0813 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9660 - student_loss: 0.0822 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9658 - student_loss: 0.0827 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9672 - student_loss: 0.0847 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9686 - student_loss: 0.0819 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9698 - student_loss: 0.0811 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9715 - student_loss: 0.0792 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9684 - student_loss: 0.0787 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.9679 - student_loss: 0.0789 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9636 - student_loss: 0.0921 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9729 - student_loss: 0.0733 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9722 - student_loss: 0.0777 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9712 - student_loss: 0.0739 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9734 - student_loss: 0.0730 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9674 - student_loss: 0.0839 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9639 - student_loss: 0.0919 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9679 - student_loss: 0.0842 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9743 - student_loss: 0.0664 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9743 - student_loss: 0.0687 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9720 - student_loss: 0.0790 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9729 - student_loss: 0.0681 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9734 - student_loss: 0.0687 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9729 - student_loss: 0.0694 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9722 - student_loss: 0.0727 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9710 - student_loss: 0.0733 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9760 - student_loss: 0.0649 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9705 - student_loss: 0.0778 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9739 - student_loss: 0.0660 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9777 - student_loss: 0.0613 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9743 - student_loss: 0.0652 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9758 - student_loss: 0.0633 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9705 - student_loss: 0.0856 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9746 - student_loss: 0.0654 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9743 - student_loss: 0.0626 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 16ms/step - binary_accuracy: 0.9748 - student_loss: 0.0674 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 4s 17ms/step - binary_accuracy: 0.9743 - student_loss: 0.0679 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.9680 - student_loss: 0.0854\n",
      "[[619  14]\n",
      " [ 13 198]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "0.9680094718933105\n",
      "student_specificity\n",
      "0.9778830963665087\n",
      "student_sensitivity\n",
      "0.9383886255924171\n",
      "student_precision\n",
      "0.9339622641509434\n",
      "student_recall\n",
      "0.9383886255924171\n",
      "student_frr\n",
      "0.061611374407582936\n",
      "student_far\n",
      "0.022116903633491312\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_6.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "headed-mission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "excessive-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmpshs5rx31.h5\n",
      "Saved student model to: /tmp/tmp86tvmk7o.h5\n",
      "Size of gzipped Teacher model: 427745.00 bytes\n",
      "Size of gzipped Student model: 13722.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
