{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excessive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inner-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(777)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    \n",
    "  try:\n",
    "      \n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      \n",
    "  except RuntimeError as e:\n",
    "      \n",
    "    print(e)\n",
    "    \n",
    "class MyModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # redefine the save so it only activates after 100 epochs\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch >= 1: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attempted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메소드 train_step, test_step, compile() 오버라이딩\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \n",
    "        1) 옵티마이저 : Student 가중치를 위한 Keras 옵티마이저\n",
    "        2) 메트릭 : 평가를 위한 Keras 메트릭\n",
    "        3) student_loss_fn : Student Model의 예측값과 실제값 차이에 대한 손실 함수\n",
    "        4) distillation_loss_fn : Soft Student Model 의 예측과 Soft Teacher Model의 예측 차이에 대한 손실 함수\n",
    "        5) alpha : student_loss_fn과 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "        6) temperature : 확률 분포를 softening 하기 위한 Temperature\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass of teacher(교사의 Forward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생의 Forward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            \n",
    "            # Compute losses (Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "            \n",
    "        # Compute gradients (Gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update the metrics configured in 'compile()'. (컴파일 안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        \n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "competitive-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1052, 480, 2)\n",
      "(11, 211, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('../../datas/160hz/train_5day_160hz.mat', squeeze_me=True)['data']\n",
    "test_data = scipy.io.loadmat('../../datas/160hz/test_6day_160hz(2).mat', squeeze_me=True)['data']\n",
    "\n",
    "# sub 수\n",
    "sub_cnt = train_data.shape[0]\n",
    "\n",
    "# 3sec 데이터 크기\n",
    "data_size = 480\n",
    "\n",
    "# 1명당 3초 데이터 개수\n",
    "train_data_cnt = 1052\n",
    "test_data_cnt = 211\n",
    "\n",
    "# 3sec 480(= 160*3) 크기로 데이터 길이 설정\n",
    "train_cut_size = 504960 # 480*1052 = 504960\n",
    "test_cut_size = 101280 # 480*211 = 101280\n",
    "\n",
    "# 3sec 데이터 길이 자르기\n",
    "# train: 504,960 / test: 101,280\n",
    "train_data = train_data[:,0:train_cut_size,:]\n",
    "test_data = test_data[:,0:test_cut_size,:]\n",
    "\n",
    "# flatten(): 3D -> 1D / reshape(-1,1): -1 마지막 인덱스\n",
    "train_flatten = train_data.flatten().reshape(-1,1)\n",
    "test_flatten = test_data.flatten().reshape(-1,1)\n",
    "\n",
    "# StandardScaler(): train에 맞춰 표준화\n",
    "data_scaler = StandardScaler()\n",
    "    \n",
    "data_scaler.fit(train_flatten)\n",
    "train_scaler = data_scaler.transform(train_flatten)\n",
    "test_scaler = data_scaler.transform(test_flatten)\n",
    "    \n",
    "# train, test 데이터 reshape\n",
    "train_data = train_scaler.reshape(train_data_cnt * sub_cnt, data_size, 2) \n",
    "test_data = test_scaler.reshape(test_data_cnt * sub_cnt, data_size, 2)\n",
    "\n",
    "#train data를 sub:other=1:1로 만들기 위해서 각 sub 추출\n",
    "train_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    train_data_each.insert(i, train_data[i*train_data_cnt:(i+1)*train_data_cnt, :, :])\n",
    "print(np.shape(train_data_each))\n",
    "\n",
    "#test data를 sub:other=1:3로 만들기 위해서 각 sub 추출\n",
    "test_data_each = []\n",
    "for i in range(sub_cnt):\n",
    "    test_data_each.insert(i, test_data[i*test_data_cnt:(i+1)*test_data_cnt, :, :])\n",
    "print(np.shape(test_data_each))\n",
    "\n",
    "# sub number\n",
    "sub_num = 9\n",
    "\n",
    "#1 to 3 비율로 설정\n",
    "ratio = 3\n",
    "\n",
    "train_data_n = train_data_each[sub_num]\n",
    "test_data_n = test_data_each[sub_num]\n",
    "\n",
    "# train data를 sub:other = 1:3으로 만들기\n",
    "# 3초 덩어리 개수 1052 : 3156\n",
    "# => 315 * 4 + 316 * 6 = 1260 + 1896 = 3156\n",
    "\n",
    "# test data를 sub:other = 1:3로 만들기\n",
    "# 3초 덩어리 개수 211 : 633\n",
    "# 63 * 7 + 64 * 3 = 633\n",
    "\n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 4:\n",
    "        cnt = cnt + 1\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 315)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 4:\n",
    "        train_data_n = np.append(train_data_n, np.array(random.sample(list(train_data_each[j]), 316)), axis = 0)\n",
    "#     print(\"train_data_n.shape\")\n",
    "#     print(train_data_n.shape)\n",
    "#     print(\"train_data_n\")\n",
    "#     print(train_data_n)\n",
    "        \n",
    "cnt = 0\n",
    "for j in range(sub_cnt):\n",
    "    if j != sub_num and cnt < 7:\n",
    "        cnt = cnt + 1\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 63)), axis = 0)\n",
    "    elif j != sub_num and cnt >= 7:\n",
    "        test_data_n = np.append(test_data_n, np.array(random.sample(list(test_data_each[j]), 64)), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "train_label = np.zeros(train_data_cnt*(ratio+1))\n",
    "test_label = np.zeros(test_data_cnt*(ratio+1))\n",
    "\n",
    "for j in range(len(train_label)):\n",
    "    if (j < train_data_cnt):\n",
    "        train_label[j] = 1\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if (j < test_data_cnt):\n",
    "        test_label[j] = 1\n",
    "        \n",
    "train_data_shuffled, train_label_shuffled = sk.utils.shuffle(train_data_n, train_label, random_state = 0)\n",
    "\n",
    "# val_data_set = train_data_shuffled[:train_data_cnt]\n",
    "# train_data_set = train_data_shuffled[train_data_cnt:]\n",
    "\n",
    "# val_label_set = train_label_shuffled[:train_data_cnt]\n",
    "# train_label_set = train_label_shuffled[train_data_cnt:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data_shuffled, train_label_shuffled), (test_data_n, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "velvet-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 6, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 57, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5584115172928684),\n",
    "        layers.LSTM(184),\n",
    "        layers.Dense(67, activation = 'relu'),\n",
    "        layers.Dense(193, activation = 'relu'),\n",
    "        layers.Dense(8, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(480, 2)),\n",
    "        layers.Conv1D(filters = 16, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Conv1D(filters = 8, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling1D(3),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.LSTM(20),\n",
    "        layers.Dense(5, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "renewable-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 480, 6)            42        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 160, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 160, 57)           1083      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 53, 57)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 53, 57)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 184)               178112    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 67)                12395     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 193)               13124     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 1552      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 206,317\n",
      "Trainable params: 206,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.4621 - binary_accuracy: 0.7854\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.3331 - binary_accuracy: 0.8538\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.3176 - binary_accuracy: 0.8645\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.2460 - binary_accuracy: 0.8962\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 10s 47ms/step - loss: 0.1747 - binary_accuracy: 0.9330\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 10s 47ms/step - loss: 0.1651 - binary_accuracy: 0.9354\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 10s 48ms/step - loss: 0.1147 - binary_accuracy: 0.9598\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 10s 46ms/step - loss: 0.1152 - binary_accuracy: 0.9570\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0878 - binary_accuracy: 0.9717\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.0821 - binary_accuracy: 0.9703\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0810 - binary_accuracy: 0.9698\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 10s 45ms/step - loss: 0.0880 - binary_accuracy: 0.9689\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0735 - binary_accuracy: 0.9731\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0589 - binary_accuracy: 0.9808\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 10s 45ms/step - loss: 0.0689 - binary_accuracy: 0.9736\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 10s 45ms/step - loss: 0.0672 - binary_accuracy: 0.9753\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.0490 - binary_accuracy: 0.9834\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0473 - binary_accuracy: 0.9812\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0492 - binary_accuracy: 0.9829\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0452 - binary_accuracy: 0.9831\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 9s 44ms/step - loss: 0.0525 - binary_accuracy: 0.9815\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0444 - binary_accuracy: 0.9829\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0537 - binary_accuracy: 0.9810\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 9s 44ms/step - loss: 0.0356 - binary_accuracy: 0.9862\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 9s 44ms/step - loss: 0.0395 - binary_accuracy: 0.9860\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0346 - binary_accuracy: 0.9879\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 9s 45ms/step - loss: 0.0324 - binary_accuracy: 0.9876\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0447 - binary_accuracy: 0.9846\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 9s 44ms/step - loss: 0.0374 - binary_accuracy: 0.9872\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0388 - binary_accuracy: 0.9867\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0385 - binary_accuracy: 0.9865\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0301 - binary_accuracy: 0.9891\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0308 - binary_accuracy: 0.9886\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0327 - binary_accuracy: 0.9874\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0390 - binary_accuracy: 0.9850\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.0359 - binary_accuracy: 0.9876\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.0369 - binary_accuracy: 0.9886\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0193 - binary_accuracy: 0.9941\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0290 - binary_accuracy: 0.9905\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.0222 - binary_accuracy: 0.9922\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0302 - binary_accuracy: 0.9886\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 9s 44ms/step - loss: 0.0262 - binary_accuracy: 0.9910\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0316 - binary_accuracy: 0.9895\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0172 - binary_accuracy: 0.9941\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0219 - binary_accuracy: 0.9941\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0241 - binary_accuracy: 0.9924\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0364 - binary_accuracy: 0.9872\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0247 - binary_accuracy: 0.9914\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.0254 - binary_accuracy: 0.9910\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.0175 - binary_accuracy: 0.9936\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0209 - binary_accuracy: 0.9922\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.0229 - binary_accuracy: 0.9912\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0232 - binary_accuracy: 0.9917\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0189 - binary_accuracy: 0.9919\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.0168 - binary_accuracy: 0.9941\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.0212 - binary_accuracy: 0.9938\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0236 - binary_accuracy: 0.9919\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0124 - binary_accuracy: 0.9957\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0225 - binary_accuracy: 0.9912\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 8s 40ms/step - loss: 0.0218 - binary_accuracy: 0.9907\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0236 - binary_accuracy: 0.9926\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.0241 - binary_accuracy: 0.9912\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.0179 - binary_accuracy: 0.9948\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 8s 36ms/step - loss: 0.0105 - binary_accuracy: 0.9955\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 8s 36ms/step - loss: 0.0156 - binary_accuracy: 0.9948\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 8s 36ms/step - loss: 0.0075 - binary_accuracy: 0.9971\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0221 - binary_accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0185 - binary_accuracy: 0.9938\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0153 - binary_accuracy: 0.9948\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0140 - binary_accuracy: 0.9950\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0158 - binary_accuracy: 0.9933\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0099 - binary_accuracy: 0.9962\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0106 - binary_accuracy: 0.9967\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0137 - binary_accuracy: 0.9950\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0125 - binary_accuracy: 0.9952\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0078 - binary_accuracy: 0.9979\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0146 - binary_accuracy: 0.9950\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0133 - binary_accuracy: 0.9955\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0143 - binary_accuracy: 0.9950\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0140 - binary_accuracy: 0.9957\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0089 - binary_accuracy: 0.9974: 0s - loss: 0.0094 - binary_accur\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0082 - binary_accuracy: 0.9969\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0133 - binary_accuracy: 0.9967\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0073 - binary_accuracy: 0.9979\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0136 - binary_accuracy: 0.9955\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0101 - binary_accuracy: 0.9964\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0090 - binary_accuracy: 0.9971\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0115 - binary_accuracy: 0.9957\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0056 - binary_accuracy: 0.9979\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0074 - binary_accuracy: 0.9976\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0085 - binary_accuracy: 0.9967\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0122 - binary_accuracy: 0.9955\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0118 - binary_accuracy: 0.9964\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0091 - binary_accuracy: 0.9971\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0085 - binary_accuracy: 0.9967\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0049 - binary_accuracy: 0.9981\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0064 - binary_accuracy: 0.9983\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0087 - binary_accuracy: 0.9971\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0056 - binary_accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0083 - binary_accuracy: 0.9981\n",
      "27/27 - 0s - loss: 0.0576 - binary_accuracy: 0.9882\n",
      "[[623  10]\n",
      " [  0 211]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "teacher_accuracy\n",
      "0.9881516695022583\n",
      "teacher_specificity\n",
      "0.9842022116903634\n",
      "teacher_sensitivity\n",
      "1.0\n",
      "teacher_precision\n",
      "0.9547511312217195\n",
      "teacher_recall\n",
      "1.0\n",
      "teacher_frr\n",
      "0.0\n",
      "teacher_far\n",
      "0.01579778830963665\n"
     ]
    }
   ],
   "source": [
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0008547152588812913),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "hist = teacher.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "teacher.save('Teacher_Model_10.h5')\n",
    "\n",
    "teacher_loss, teacher_acc = teacher.evaluate(x_test, y_test, verbose = 2)\n",
    "teacher_pred = teacher.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(teacher_pred)):\n",
    "    if(0.5 <= teacher_pred[i]):\n",
    "        teacher_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        teacher_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, teacher_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "teacher_sen = conf_matrix[1][1] / row[1]\n",
    "teacher_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "teacher_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "teacher_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "teacher_prec = conf_matrix[1][1] / conf_col[1]\n",
    "teacher_recall = conf_matrix[1][1] / conf_row[1]\n",
    "    \n",
    "print('teacher_accuracy')\n",
    "print(teacher_acc)\n",
    "print('teacher_specificity')\n",
    "print(teacher_spe)\n",
    "print('teacher_sensitivity')\n",
    "print(teacher_sen)\n",
    "print('teacher_precision')\n",
    "print(teacher_prec)\n",
    "print('teacher_recall')\n",
    "print(teacher_recall)\n",
    "print('teacher_frr')\n",
    "print(teacher_frr)\n",
    "print('teacher_far')\n",
    "print(teacher_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accurate-badge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 4s 20ms/step - binary_accuracy: 0.7602 - student_loss: 0.4880 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.8505 - student_loss: 0.3274 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.8836 - student_loss: 0.2807 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9163 - student_loss: 0.2071 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9337 - student_loss: 0.1621 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9503 - student_loss: 0.1408 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9518 - student_loss: 0.1248 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9513 - student_loss: 0.1309 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9641 - student_loss: 0.0986 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9667 - student_loss: 0.1023 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9696 - student_loss: 0.0883 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9596 - student_loss: 0.1044 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9708 - student_loss: 0.0841 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9693 - student_loss: 0.0812 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9712 - student_loss: 0.0800 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9691 - student_loss: 0.0843 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9746 - student_loss: 0.0688 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9734 - student_loss: 0.0748 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9720 - student_loss: 0.0793 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9739 - student_loss: 0.0764 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9717 - student_loss: 0.0738 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9767 - student_loss: 0.0665 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9786 - student_loss: 0.0654 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9774 - student_loss: 0.0615 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9774 - student_loss: 0.0601 - distillation_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9758 - student_loss: 0.0714 - distillation_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9772 - student_loss: 0.0602 - distillation_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9781 - student_loss: 0.0665 - distillation_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9739 - student_loss: 0.0706 - distillation_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9774 - student_loss: 0.0671 - distillation_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9748 - student_loss: 0.0688 - distillation_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9767 - student_loss: 0.0646 - distillation_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9769 - student_loss: 0.0552 - distillation_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9796 - student_loss: 0.0597 - distillation_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9781 - student_loss: 0.0627 - distillation_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9817 - student_loss: 0.0596 - distillation_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9760 - student_loss: 0.0662 - distillation_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 18ms/step - binary_accuracy: 0.9758 - student_loss: 0.0653 - distillation_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9815 - student_loss: 0.0486 - distillation_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9788 - student_loss: 0.0575 - distillation_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9812 - student_loss: 0.0552 - distillation_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9810 - student_loss: 0.0571 - distillation_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9810 - student_loss: 0.0571 - distillation_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9817 - student_loss: 0.0514 - distillation_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9748 - student_loss: 0.0605 - distillation_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9803 - student_loss: 0.0535 - distillation_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9800 - student_loss: 0.0544 - distillation_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9786 - student_loss: 0.0541 - distillation_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9793 - student_loss: 0.0601 - distillation_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9800 - student_loss: 0.0512 - distillation_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9808 - student_loss: 0.0545 - distillation_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9796 - student_loss: 0.0521 - distillation_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9808 - student_loss: 0.0513 - distillation_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9810 - student_loss: 0.0475 - distillation_loss: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9834 - student_loss: 0.0472 - distillation_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9829 - student_loss: 0.0545 - distillation_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9800 - student_loss: 0.0529 - distillation_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9827 - student_loss: 0.0503 - distillation_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9831 - student_loss: 0.0523 - distillation_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9829 - student_loss: 0.0523 - distillation_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9791 - student_loss: 0.0526 - distillation_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9831 - student_loss: 0.0479 - distillation_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9824 - student_loss: 0.0446 - distillation_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9817 - student_loss: 0.0475 - distillation_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9784 - student_loss: 0.0589 - distillation_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9824 - student_loss: 0.0447 - distillation_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9846 - student_loss: 0.0407 - distillation_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9834 - student_loss: 0.0448 - distillation_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9862 - student_loss: 0.0437 - distillation_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9824 - student_loss: 0.0454 - distillation_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9848 - student_loss: 0.0419 - distillation_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9824 - student_loss: 0.0474 - distillation_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9810 - student_loss: 0.0518 - distillation_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9843 - student_loss: 0.0430 - distillation_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9838 - student_loss: 0.0426 - distillation_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9838 - student_loss: 0.0484 - distillation_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9836 - student_loss: 0.0418 - distillation_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9853 - student_loss: 0.0438 - distillation_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9865 - student_loss: 0.0380 - distillation_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9846 - student_loss: 0.0476 - distillation_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9829 - student_loss: 0.0445 - distillation_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9860 - student_loss: 0.0372 - distillation_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9817 - student_loss: 0.0497 - distillation_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9850 - student_loss: 0.0395 - distillation_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9827 - student_loss: 0.0437 - distillation_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9857 - student_loss: 0.0443 - distillation_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9848 - student_loss: 0.0437 - distillation_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9862 - student_loss: 0.0394 - distillation_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9841 - student_loss: 0.0486 - distillation_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9848 - student_loss: 0.0392 - distillation_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9862 - student_loss: 0.0409 - distillation_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9857 - student_loss: 0.0374 - distillation_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9822 - student_loss: 0.0486 - distillation_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9886 - student_loss: 0.0332 - distillation_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9829 - student_loss: 0.0496 - distillation_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9867 - student_loss: 0.0377 - distillation_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9855 - student_loss: 0.0407 - distillation_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9822 - student_loss: 0.0431 - distillation_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9895 - student_loss: 0.0369 - distillation_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 4s 19ms/step - binary_accuracy: 0.9872 - student_loss: 0.0362 - distillation_loss: 0.0000e+00\n",
      "27/27 - 0s - binary_accuracy: 0.9870 - student_loss: 0.0379\n",
      "[[630   3]\n",
      " [  8 203]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [633 211]\n",
      "student_accuracy\n",
      "0.9869668483734131\n",
      "student_specificity\n",
      "0.995260663507109\n",
      "student_sensitivity\n",
      "0.9620853080568721\n",
      "student_precision\n",
      "0.9854368932038835\n",
      "student_recall\n",
      "0.9620853080568721\n",
      "student_frr\n",
      "0.037914691943127965\n",
      "student_far\n",
      "0.004739336492890996\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "  \n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(x_train, y_train, batch_size=20, epochs=100, verbose = 1)\n",
    "\n",
    "# save model\n",
    "student.save('Student_Model_10.h5')\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "student_acc = distiller.evaluate(x_test, y_test, verbose = 2)\n",
    "student_pred = student.predict(x_test)\n",
    "    \n",
    "# 확률이 0.5이상이면 자신(1), 작으면 타인(0)\n",
    "for i in range(len(student_pred)):\n",
    "    if(0.5 <= student_pred[i]):\n",
    "        student_pred[i] = 1\n",
    "\n",
    "    else:\n",
    "        student_pred[i] = 0\n",
    "        \n",
    "# confusion matrix 생성\n",
    "conf_matrix = confusion_matrix(y_test, student_pred)\n",
    "    \n",
    "#############################################################\n",
    "#       conf_matrix[0][0] = TN      conf_matrix[0][1] = FP  #\n",
    "#       conf_matrix[1][0] = FN      conf_matrix[1][1] = TP  #\n",
    "#############################################################\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(conf_matrix)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, conf_matrix[i, j], color=\"white\")\n",
    "\n",
    "plt.title('CNN+LSTM model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sum 이용 각 행 더하기\n",
    "row = conf_matrix.sum(axis=1)\n",
    "print('\\n', row)\n",
    "\n",
    "conf_row = conf_matrix.sum(axis = 1)\n",
    "conf_col = conf_matrix.sum(axis = 0)\n",
    "\n",
    "# row[0] = spec의 분모, row[1] = sens의 분모\n",
    "\n",
    "student_sen = conf_matrix[1][1] / row[1]\n",
    "student_spe = conf_matrix[0][0] / row[0]\n",
    "    \n",
    "student_frr = conf_matrix[1][0] / (conf_matrix[1][1]+conf_matrix[1][0])\n",
    "student_far = conf_matrix[0][1] / (conf_matrix[0][1]+conf_matrix[0][0])\n",
    "    \n",
    "student_prec = conf_matrix[1][1] / conf_col[1]\n",
    "student_recall = conf_matrix[1][1] / conf_row[1]\n",
    "\n",
    "print('student_accuracy')\n",
    "print(student_acc)\n",
    "print('student_specificity')\n",
    "print(student_spe)\n",
    "print('student_sensitivity')\n",
    "print(student_sen)\n",
    "print('student_precision')\n",
    "print(student_prec)\n",
    "print('student_recall')\n",
    "print(student_recall)\n",
    "print('student_frr')\n",
    "print(student_frr)\n",
    "print('student_far')\n",
    "print(student_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "headed-mission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# gzip을 통해 모델을 실제로 압축하고 압축된 크기를 측정\n",
    "# 모델의 크기(바이트)를 반환한다.\n",
    "def get_gzipped_model_size(file):\n",
    "  \n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "constitutional-wholesale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved teacher model to: /tmp/tmpha_5riqx.h5\n",
      "Saved student model to: /tmp/tmpyodhymty.h5\n",
      "Size of gzipped Teacher model: 770209.00 bytes\n",
      "Size of gzipped Student model: 13732.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, teacher_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(teacher, teacher_file, include_optimizer=False)\n",
    "print('Saved teacher model to:', teacher_file)\n",
    "\n",
    "# 임시 파일을 생성하고 그 파일에 학습한 모델을 저장한다.\n",
    "# keras_file는 file path\n",
    "_, student_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(student, student_file, include_optimizer=False)\n",
    "print('Saved student model to:', student_file)\n",
    "\n",
    "print(\"Size of gzipped Teacher model: %.2f bytes\" % (get_gzipped_model_size(teacher_file)))\n",
    "print(\"Size of gzipped Student model: %.2f bytes\" % (get_gzipped_model_size(student_file)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
